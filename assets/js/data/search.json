[ { "title": "[WebLogic] Serializable 란 무엇인가?", "url": "/posts/weblogic_tip_9/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Serializable", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. 바이트 스트림(Byte Stream) 3. 고수준과 저수준 4. 객체는 그래프 5. Serializable 6. RMI1. 개요Serializable 란 무엇인가?2. 바이트 스트림(Byte Stream)통신(네트워크, 입출력I/O)은 바이트 단위로 이루어 집니다.그리고 이 통신을 스트림 이라고 합니다.즉, 통신은 바이트 스트림으로 이루어진다고 할 수 있습니다.3. 고수준과 저수준그리고 이때 통신은 하드웨어적인 저수준과, 소프트웨어적인 고수준으로 구분할 수 있습니다.고수준 통신을 사용하는 소프트웨어에서 문자 “a”를 전송하기 위해서는 저수준인 1바이트 0110 0001로 하드웨어에 전달해야 합니다.여기서 하드웨어는 이더넷 케이블이나 랜카드, 라우터 등을 의미합니다.4. 객체는 그래프integer, byte, long, boolean, string, char 와 같은 데이터들은 바이트 단위로 이루어져 있기 때문에 통신에서 걱정할 필요가 없습니다.하드웨어에서 금방 이해할 수 있는 저수준으로 이루어져 있기 때문입니다.하지만 객체는 구조가 달라 일반적으로 통신에 사용할 수 없습니다.가령 클래스 객체는 그래프라는 형식으로 이루어져 있습니다.예로 아래 클래스 gtplus는 몇개의 변수들과 메서드를 가지고 있습니다.class gtplus{ string ...; int ...; boolean ...; public newFamily(){ string ...; }}그래프는 다음과 같습니다.클래스 내의 string, int 등은 통신에서 보낼 수 있지만, 클래스 객체는 연결고리(레퍼런스)가 그래프 형식이기 때문에 정리할 필요가 있습니다.5. Serializable여기서 정리를 위해 바이트 단위처럼 일렬로 만드는 직렬화가 필요합니다.JDK 1.1에서 나온 직렬화는 단순히 인터페이스를 구현(implements Serializable)하는 것으로 직렬화가 됩니다.원래 그렇듯이 인터페이스 내부에는 아무런 기능도 없지만, JVM에서 이해하고 자동으로 OS에 특화된 저수준 통신에 사용할 수 있게 바꾸어 주기 때문입니다.또 객체를 전달받은 JVM은 역직렬화를 통해 저수준의 객체 데이터를 고수준으로 바꾸어 원래의 객체 상태로 완전히 복구하여 사용할 수 있게 됩니다.직렬화를 요약하자면, 객체를 전송(파일 저장, 네트워크 통신)하기 위해 그래프를 일렬로 줄 세운다고 할 수 있습니다.6. RMI직렬화 하면, RMI 통신과 연관되어 있습니다.Remote Method Invocation은 원격 메소드 호출으로써, 자바 환경에서 다른 JVM(다른 서버)의 메모리에 적재되있는 객체를 불러 마치 로컬에 구현한 것처럼 사용할 수 있습니다.EJB에서 사용되는 RMI통신은 직렬화가 되어 있는 객체여야 합니다.통신은 바이트 단위입니다.객체는 바이트 단위가 아닙니다.직렬화는 바이트 단위로 만들어줍니다." }, { "title": "[WebLogic] Serializable Test", "url": "/posts/weblogic_tip_8/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Serializable", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. 테스트 어플리케이션 3. Serializable 가 구현되지 않았을 때 4. Serializable 구현되었을 때1. 개요세션 복제 될 데이터가 직렬화 되어있는 경우와 그렇지 않은 경우를 테스트해보았습니다.이때 세션 데이터는 직렬화 구현이 필요한 클래스 객체로 구현해보았습니다.2. 테스트 어플리케이션webapp.zip 첨부파일의 FailoverTest.jsp는 원본입니다. FailoverTest_class.jsp는 페이지 로드 시 1씩 증가하는 Integer 데이터를 새로 생성한 클래스에 멤버 변수로 선언하여 저장하게 했습니다. 세션 데이터는 첨부파일의 sessionObject 클래스를 선언하여 멤버 변수에 저장합니다. package kdh; -&amp;gt; FailoverTest_class.jsp가 클래스 파일을 import 하기 위해서는 패키지화를 꼭 해야 된다고 해서 kdh로 구성하였습니다. implements Serializable -&amp;gt; Serializable를 구현하여 클래스가 세션 복제 될 수 있도록 하였습니다. serialVersionUID가 없거나 서로 다르면, 세션 복제는 되더라도 쿠키가 덮어씌워집니다. 첨부파일의 weblogic.xml에 cookie-domain을 .main.com 으로 설정했습니다. 윈도우 로컬에서 테스트하였는데, C:\\Windows\\System32\\drivers\\etc\\hosts 파일에 m1.main.com과 m2.main.com을 등록하였습니다.3. Serializable 가 구현되지 않았을 때 웹로직 인스턴스 m1, m2는 이중화 구성이며 클러스터 되었습니다. 웹로직 콘솔 -&amp;gt; Env -&amp;gt; Servers -&amp;gt; m1 / m2 -&amp;gt; Logging -&amp;gt; Advanced -&amp;gt; Standard out의 Severity level을 Debug로 설정하였습니다. -&amp;gt; Debug -&amp;gt; weblogic -&amp;gt; servlet -&amp;gt; internal -&amp;gt; session 을 체크하고 Enable 하였습니다. 참고사이트 // 2021.12.20 일 기준 404 &amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;Session attribute with name:sessionObject class:kdh.sessionObject is not serializable ane will not be replicated or persisted&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;synchronized on -4561296442252280985 and session is inUse: false and active request count is: 0&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;[HTTP Session:100078]HTTPSession with id: &quot;o3x3KA71JO-6he8QpS7zQL5qKE-c9XLj8FBFrFsLfs9wzWH6pFIr&quot; is of size 1,030 bytes.&amp;gt;&amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;The change associated with this SessionData(-4561296442252280985 or weblogic.servlet.internal.session.ReplicatedSessionData@6a648175 ) is: 1017170932&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt; SessionData.syncSession() the change is modified: false and the active request count is: 0 for -4561296442252280985 and this is: weblogic.servlet.internal.session.ReplicatedSessionData@6a648175 &amp;gt; Serializable 구현되지 않았을 때 로그4. Serializable 구현되었을 때&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;[HTTP Session:100046]Creating new session with ID: LLl3LO-KBxD9qlT40AsWbLjP5gJfcf7MB-5C5FBWVUBM8SPXDRzV for Web application: /webapp.&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;[HTTP Session:100050]The current server is becoming the primary server for replicated session ID: LLl3LO-KBxD9qlT40AsWbLjP5gJfcf7MB-5C5FBWVUBM8SPXDRzV.&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;sessionId:LLl3LO-KBxD9qlT40AsWbLjP5gJfcf7MB-5C5FBWVUBM8SPXDRzV associated with roid:-4561296442252280984&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;[HTTP Session:100077]HTTPSession attribute: &quot;sessionObject&quot; is of size 61 bytes.&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;Checksum for attribute &#39;sessionObject&#39;, value: 2071176261&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;synchronized on -4561296442252280984 and session is inUse: false and active request count is: 0&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;[HTTP Session:100078]HTTPSession with id: &quot;LLl3LO-KBxD9qlT40AsWbLjP5gJfcf7MB-5C5FBWVUBM8SPXDRzV&quot; is of size 1,242 bytes.&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;The change associated with this SessionData(-4561296442252280984 or weblogic.servlet.internal.session.ReplicatedSessionData@49221aa7 ) is: 995501008&amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt; SessionData.syncSession() the change is modified: true and the active request count is: 0 for -4561296442252280984 and this is: weblogic.servlet.internal.session.ReplicatedSessionData@49221aa7 &amp;gt;&amp;lt;Debug&amp;gt; &amp;lt;HttpSessions&amp;gt; &amp;lt;BEA-000000&amp;gt; &amp;lt;Replicating session : -4561296442252280984 and weblogic.servlet.internal.session.ReplicatedSessionData@49221aa7 &amp;gt;" }, { "title": "[WebLogic] Maven 간단히 해볼까..?", "url": "/posts/weblogic_tip_7/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Mavel", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. Version 별 문서 3. Maven1. 개요Maven 아주 진짜 너무 간단하게..2. Version 별 문서웹로직 11g 메이븐 문서웹로직 12c 메이븐 문서3. MavenPhase를 실행하면, Phase에 속한 모든 goal가 실행된다.Table 3.1 Maven Lifecycle Phases은 maven의 기본 라이프 사이클 테이블을 보여주는 것이고,Table 3.2 Common Mapping of Goals to Phases는 웹로직에서 사용하는 단계와 골 들을 보여주는 정보이다.즉 메이븐에서 제공하는 Table3.1을 웹로직에 맞는 Table3.2로 오라클이 maven 프로젝트를 개발하였다.# mvn package -DpomFile=pom.xml 위 명령은 package Phase를 실행 시키는 것으로써, 해당하는 Goal은 appc만 있다. (-DpomFile 생략시 현재 위치 pom.xml)# mvn validate 위 명령은 validate Phase를 실행하고, ws-clientgen과 ws-wsdlc를 차례대로 실행한다.# mvn weblogic:ws-wsdlc 위 명령은 validate Phase에서 ws-clientgen 을 실행시키지 않고 ws-wsdlc만 실행시키는 방법이다.여기 참고" }, { "title": "[WebLogic] HttpSession, Cookie, JSESSIONID", "url": "/posts/weblogic_tip_6/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Session, Cookie, JSESSIONID", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. Cookie-Name 테스트 2.1 HttpSession과 Cookie, JSESSIONID (1). HttpSession (2). Cookie (3). JSESSIONID 2.2 apache에 cookie-name을 TESTSESSION으로 변경하고 cookie_detail.jsp 요청 - 1회 (1). 웹서버의 웹로직 모듈은 WebLogicCluster의 파라메터를 확인합니다. (2). 첫번째 서버(testlinux1.com)가 Alive 상태인지 확인합니다. (3). 두번째 서버(testlinux2.com)가 Alive 상태인지 확인합니다. (4). 응답한 서버가 2개이므로 노드 배열(길이 2)을 생성하고 서버들을 할당합니다. (5). 첫번째 서버에 연결합니다. (6). cookie_detail.jsp 의 2453 라인에 의해 소켓 연결 (7). 웹서버는 브라우저로부터 HTTP 헤더를 전달받아 파싱을 수행합니다. (8). HTTP 헤더는 총 6개의 값으로 구성되어 있음을 확인합니다. (9). 웹서버는 헤더 파싱을 끝내고 웹로직 서버로 헤더를 전달하기 위해 GET 방식을 사용합니다. (10). 웹 서버는 웹로직 서버로 헤더를 전달합니다. (11). 웹로직 서버는 헤더를 분석하고 HTTP 200 코드와 함께 웹서버에게 RESPONSE할 페이지를 생성합니다. (12). 웹로직 서버가 만든 헤더 정보를 웹서버가 받아 파싱합니다. (13). 헤더 파싱을 끝내고 200 OK 상태로 표현합니다. (14). 이 부분은, 가장 마지막에 접속한 서버를 표시하는 것 같습니다. (15). 헤더에서 클러스터 목록, JVM ID를 구하고 파싱합니다. (16). 위 파싱에 의해, 처음처럼 두개의 서버를 유지하고 있음을 알 수 있습니다. (17). 클라이언트의 헤더에 GMT(+9시간) 시간을 넣습니다. (18). 클라이언트의 헤더에 JSESSIONID 쿠키를 할당합니다. (19). cookie_detail.jsp와 연결을 끊습니다. 2.3 apache에 cookie-name을 TESTSESSION으로 변경하고 cookie_detail.jsp 요청 - 2회 (1). 같은 클라이언트(브라우저)가 다시 똑같은 페이지를 요청할 경우 웹로직 첫번째 서버는 클라이언트의 HTTP 헤더에서 사용 가능한 JSESSIONID 쿠키를 발견합니다. (2). 클라이언트는 Primary 서버로 연결되며, 쿠키로 TESTSESSION을 찾습니다. 하지만 Primary 서버와 클라이언트에는 TESTSESSION 쿠키가 없습니다. 웹로직 서버는 Primary 와 Secondary를 바꾸어 JSESSIONID 를 다시 할당합니다. 다시 할당 하는 이유는 다음 연결때는 Secondary로 가게 되기 때문입니다. 2.4 apache와 weblogic의 cookie name을 TESTSESSION으로 동일 설정 (1). 첫 접속 시 웹로직은 TESTSESSION으로 쿠키를 할당합니다. (2). 두번째 접속 시 클라이언트가 요청하는 TESTSESSION은 웹로직과 동일하므로 쿠키를 발견하고, 파싱하여 정보를 얻을 수 있습니다. (3). 쿠키에서 세션 타임아웃 방지를 위한 시간만 갱신합니다. 2.5 apache cookie name은 TESTSESSION2, wls cookie name은 TESTSESSION1 일 때 3. JSESSION ID 테스트 2.1 같은 cookie 를 발급하는 cookie_detail.jsp 호출 4. 세션 공유 테스트 4.1 도메인 단위 4.2 어플리케이션 단위 (1). ear 구조 1. 개요테스트와 디버그 로그를 통해 HttpSession, Cookie, JSESSIONID 를 구체적으로 공부한다.2. Cookie-Name 테스트2.1 HttpSession과 Cookie, JSESSIONID클라이언트의 브라우저에서 사용하는 HTTP 통신은 stateless(상태 무지속)방식입니다.stateless는 클라이언트(브라우저)의 요청(request)과 서버의 응답(response) 후에는 소켓을 끊는 단발성 통신 방식입니다.여기서 세션이나 쿠키 등을 이용하여 서버는 신규 클라이언트와 오래된 클라이언트를 구별할 수 있습니다.(1). HttpSession웹 서버는 클라이언트를 구분하기 위해 클라이언트의 PC에 구별되는 세션 ID(긴 문자열)를 생성합니다.클라이언트가 웹 서버에 다시 요청 시, 서버는 이 세션 존재여부로 신규 유저인지, 이미 로그인한 유저인지 알 수 있습니다.(2). Cookiecookie는 파일로 저장되기 때문에 멀웨어 등의 악성 프로그램으로 유출되어 피해가 생길 수 있습니다.세션은 쿠키에 저장되는 정보들을 파일로 저장하는 대신 서버와 클라이언트의 메모리 영역에 복사합니다.하지만 클라이언트 수만큼 세션이 메모리 공간을 차지합니다.(3). JSESSIONIDJSESSIONID는 WAS에서 사용되는 개념입니다.일반적인 웹 어플리케이션은 HttpSession이나 Cookie로 클라이언트를 구별합니다.하지만 WAS에는 이러한 웹 어플리케이션이 여러개가 존재합니다.이 하나하나의 어플리케이션들도 클라이언트를 구별하기 위해 유니크한 JSESSIONID를 메모리에 저장하여 구별합니다.2.2 apache에 cookie-name을 TESTSESSION으로 변경하고 cookie_detail.jsp 요청 - 1회(1). 웹서버의 웹로직 모듈은 WebLogicCluster의 파라메터를 확인합니다.[debug] BaseProxy.cpp(1915): [client 192.168.56.1] weblogic: parseServerList: Socket Address hostnames &#39;testlinux1.com:12001,testlinux2.com:12001&#39;(2). 첫번째 서버(testlinux1.com)가 Alive 상태인지 확인합니다.[debug] BaseProxy.cpp(1979): [client 192.168.56.1] weblogic: Host extracted from serverlist is [testlinux1.com][debug] BaseProxy.cpp(2030): [client 192.168.56.1] weblogic: parseServerList: trying IP addr 192.168.56.2[debug] BaseProxy.cpp(2066): [client 192.168.56.1] weblogic: parseServerList: socket and connect succeeded[debug] BaseProxy.cpp(2087): [client 192.168.56.1] weblogic: parseServerList: IP from socket Address [192.168.56.2](3). 두번째 서버(testlinux2.com)가 Alive 상태인지 확인합니다.[debug] BaseProxy.cpp(1979): [client 192.168.56.1] weblogic: Host extracted from serverlist is [testlinux2.com][debug] BaseProxy.cpp(2030): [client 192.168.56.1] weblogic: parseServerList: trying IP addr 192.168.56.3[debug] BaseProxy.cpp(2066): [client 192.168.56.1] weblogic: parseServerList: socket and connect succeeded[debug] BaseProxy.cpp(2087): [client 192.168.56.1] weblogic: parseServerList: IP from socket Address [192.168.56.3](4). 응답한 서버가 2개이므로 노드 배열(길이 2)을 생성하고 서버들을 할당합니다.BaseProxy.cpp(3005): [client 192.168.56.1] weblogic: Initializing lastIndex=0 for a list of length=2[Mon Jul 06 09:37:26 2015] [debug] BaseProxy.cpp(509): [client 192.168.56.1] weblogic: getListNode: created a new server node: id=&#39;testlinux1.com:12001,testlinux2.com:12001&#39; server_name=&#39;testlinux1.com&#39;, port=&#39;80&#39;(5). 첫번째 서버에 연결합니다.[debug] ApacheProxy.cpp(2421): [client 192.168.56.1] weblogic: Trying a pooled connection for &#39;192.168.56.2/12001/12001&#39;[debug] BaseProxy.cpp(3035): [client 192.168.56.1] weblogic: getPooledConn: found a host and port/securePort match[debug] BaseProxy.cpp(3086): [client 192.168.56.1] weblogic: getPooledConn: No more connections in the pool for Host[192.168.56.2] Port[12001] SecurePort[12001](6). cookie_detail.jsp 의 2453 라인에 의해 소켓 연결[debug] ApacheProxy.cpp(2453): [client 192.168.56.1] weblogic: general list: trying connect to &#39;192.168.56.2&#39;/12001/12001 at line 2453 for &#39;/webapp/cookie_detail.jsp&#39;[debug] URL.cpp(1785): [client 192.168.56.1] weblogic: URL::Connect: Connected successfully[debug] URL.cpp(1824): [client 192.168.56.1] weblogic: SSL is not configured for this connection[debug] URL.cpp(1844): [client 192.168.56.1] weblogic: Local Port of the socket is 51741[debug] URL.cpp(1850): [client 192.168.56.1] weblogic: Remote Host 192.168.56.2 Remote Port 51741[debug] ApacheProxy.cpp(2487): [client 192.168.56.1] weblogic: general list: created a new connection to &#39;192.168.56.2&#39;/12001 for &#39;/webapp/cookie_detail.jsp&#39;, Local port:51741(7). 웹서버는 브라우저로부터 HTTP 헤더를 전달받아 파싱을 수행합니다.[debug] BaseProxy.cpp(567): [client 192.168.56.1] weblogic: Entering method BaseProxy::sendRequest[debug] BaseProxy.cpp(1219): [client 192.168.56.1] weblogic: Entering method BaseProxy::parse_headers(8). HTTP 헤더는 총 6개의 값으로 구성되어 있음을 확인합니다.[debug] BaseProxy.cpp(1237): [client 192.168.56.1] weblogic: No of headers =6[info] [client 192.168.56.1] weblogic: Header from client:[Host]=[testlinux1.com][info] [client 192.168.56.1] weblogic: Header from client:[Connection]=[keep-alive][info] [client 192.168.56.1] weblogic: Header from client:[Accept]=[text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8][client 192.168.56.1] weblogic: Header from client:[User-Agent]=[Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36][client 192.168.56.1] weblogic: Header from client:[Accept-Encoding]=[gzip, deflate, sdch][info] [client 192.168.56.1] weblogic: Header from client:[Accept-Language]=[en,ko;q=0.8,en-US;q=0.6](9). 웹서버는 헤더 파싱을 끝내고 웹로직 서버로 헤더를 전달하기 위해 GET 방식을 사용합니다.[debug] BaseProxy.cpp(1413): [client 192.168.56.1] weblogic: Exiting method BaseProxy::parse_headers[debug] BaseProxy.cpp(577): [client 192.168.56.1] weblogic: parse_client_headers is done[debug] BaseProxy.cpp(681): [client 192.168.56.1] weblogic: Method is GET(10). 웹 서버는 웹로직 서버로 헤더를 전달합니다.[info] [client 192.168.56.1] weblogic: URL::sendHeaders(): meth=&#39;GET&#39; file=&#39;/webapp/cookie_detail.jsp&#39; protocol=&#39;HTTP/1.1&#39;[info] [client 192.168.56.1] weblogic: Header to WLS: [Host]=[testlinux1.com][info] [client 192.168.56.1] weblogic: Header to WLS: [Accept]=[text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8][info] [client 192.168.56.1] weblogic: Header to WLS: [User-Agent]=[Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36][info] [client 192.168.56.1] weblogic: Header to WLS: [Accept-Encoding]=[gzip, deflate, sdch][info] [client 192.168.56.1] weblogic: Header to WLS: [Accept-Language]=[en,ko;q=0.8,en-US;q=0.6][info] [client 192.168.56.1] weblogic: Header to WLS: [Connection]=[Keep-Alive][info] [client 192.168.56.1] weblogic: Header to WLS: [WL-Proxy-SSL]=[false][info] [client 192.168.56.1] weblogic: Header to WLS: [X-Forwarded-For]=[192.168.56.1][info] [client 192.168.56.1] weblogic: Header to WLS: [WL-Proxy-Client-IP]=[192.168.56.1][info] [client 192.168.56.1] weblogic: Header to WLS: [WL-Proxy-Client-Port]=[1640][info] [client 192.168.56.1] weblogic: Header to WLS: [X-WebLogic-KeepAliveSecs]=[30][info] [client 192.168.56.1] weblogic: Header to WLS: [X-WebLogic-Force-JVMID]=[unset][info] [client 192.168.56.1] weblogic: Header to WLS: [X-WebLogic-Request-ClusterInfo]=[true] 첫 요청이므로 JVMID가 unset 입니다.(11). 웹로직 서버는 헤더를 분석하고 HTTP 200 코드와 함께 웹서버에게 RESPONSE할 페이지를 생성합니다.[debug] BaseProxy.cpp(766): [client 192.168.56.1] weblogic: About to call parseHeaders[debug] Reader.cpp(221): [client 192.168.56.1] weblogic: Reader::fill(): first=0 last=0 toRead=4096[debug] Reader.cpp(270): [client 192.168.56.1] weblogic: Reader::fill(): sysRecv returned 413[debug] URL.cpp(842): [client 192.168.56.1] weblogic: URL::parseHeaders: CompleteStatusLine set to [HTTP/1.1 200 OK][debug] URL.cpp(844): [client 192.168.56.1] weblogic: URL::parseHeaders: StatusLine set to [200 OK][debug] URL.cpp(852): [client 192.168.56.1] weblogic: URL::parseHeaders: StatusLineWithoutStatusCode set to [OK](12). 웹로직 서버가 만든 헤더 정보를 웹서버가 받아 파싱합니다.[info] [client 192.168.56.1] weblogic: Header from WLS:[Date]=[Mon, 06 Jul 2015 00:37:26 GMT][info] [client 192.168.56.1] weblogic: Header from WLS:[Content-Length]=[578][info] [client 192.168.56.1] weblogic: Header from WLS:[Content-Type]=[text/html;charset=UTF-8][info] [client 192.168.56.1] weblogic: Header from WLS:[X-WebLogic-Cluster-List]=[1104478448!testlinux1.com!12001!-1|1625602300!testlinux2.com!12001!-1][info] [client 192.168.56.1] weblogic: Header from WLS:[X-WebLogic-JVMID]=[1104478448][info] [client 192.168.56.1] weblogic: Header from WLS:[Set-Cookie]=[JSESSIONID=Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5!1104478448!1625602300; path=/; HttpOnly][info] [client 192.168.56.1] weblogic: Header from WLS:[X-WebLogic-Cluster-Hash]=[UGYKWofLj2uHaIuW02FSaDWNmdU](13). 헤더 파싱을 끝내고 200 OK 상태로 표현합니다.[debug] URL.cpp(966): [client 192.168.56.1] weblogic: parsed all headers OK[debug] BaseProxy.cpp(840): [client 192.168.56.1] weblogic: Exiting method BaseProxy::sendRequest[debug] ApacheProxy.cpp(244): [client 192.168.56.1] weblogic: sendResponse() : r-&amp;gt;status = &#39;200&#39;(14). 이 부분은, 가장 마지막에 접속한 서버를 표시하는 것 같습니다.[debug] BaseProxy.cpp(345): [client 192.168.56.1] weblogic: Free old srvrList, id=[testlinux1.com:12001,testlinux2.com:12001], server_name=[testlinux1.com], server_port=[80](15). 헤더에서 클러스터 목록, JVM ID를 구하고 파싱합니다.[debug] BaseProxy.cpp(2191): [client 192.168.56.1] weblogic: Parsing cluster list: 1104478448!testlinux1.com!12001!-1|1625602300!testlinux2.com!12001!-1[debug] BaseProxy.cpp(2498): [client 192.168.56.1] weblogic: parseJVMID: Parsing JVMID &#39;1104478448!testlinux1.com!12001!-1|1625602300!testlinux2.com!12001!-1&#39;[debug] BaseProxy.cpp(2550): [client 192.168.56.1] weblogic: parseJVMID: Actually parsing &#39;1104478448!testlinux1.com!12001!-1&#39;[debug] BaseProxy.cpp(2643): [client 192.168.56.1] weblogic: ServerInfo struct for JVMID &#39;1104478448&#39; populated, Server Details are: OrigHostInfo [testlinux1.com], isOrigHostInfoDNS [1], Host [192.168.56.2], Port [12001], SecurePort [0][debug] BaseProxy.cpp(2498): [client 192.168.56.1] weblogic: parseJVMID: Parsing JVMID &#39;1625602300!testlinux2.com!12001!-1&#39;[debug] BaseProxy.cpp(2550): [client 192.168.56.1] weblogic: parseJVMID: Actually parsing &#39;1625602300!testlinux2.com!12001!-1&#39;[debug] BaseProxy.cpp(2643): [client 192.168.56.1] weblogic: ServerInfo struct for JVMID &#39;1625602300&#39; populated, Server Details are: OrigHostInfo [testlinux2.com], isOrigHostInfoDNS [1], Host [192.168.56.3], Port [12001], SecurePort [0] testlinux1.com 의 JVM ID 는 1104478448 testlinux2.com 의 JVM ID 는 1625602300(16). 위 파싱에 의해, 처음처럼 두개의 서버를 유지하고 있음을 알 수 있습니다.[debug] BaseProxy.cpp(3005): [client 192.168.56.1] weblogic: Initializing lastIndex=0 for a list of length=2[debug] BaseProxy.cpp(380): [client 192.168.56.1] weblogic: ### Got a new Server List of length 2 ###[debug] BaseProxy.cpp(382): [client 192.168.56.1] weblogic: ###Response### : Srvr# [1] = [192.168.56.2:12001:0][debug] BaseProxy.cpp(382): [client 192.168.56.1] weblogic: ###Response### : Srvr# [2] = [192.168.56.3:12001:0](17). 클라이언트의 헤더에 GMT(+9시간) 시간을 넣습니다.[info] [client 192.168.56.1] weblogic: Hdrs to client (add):[Date]=[Mon, 06 Jul 2015 00:37:26 GMT] 이 GMT 시간은 클라이언트와 웹로직 서버가 메모리에 저장하는 세션 정보의 마지막에 포함됩니다.(18). 클라이언트의 헤더에 JSESSIONID 쿠키를 할당합니다.[info] [client 192.168.56.1] weblogic: Hdrs to client (add):[Set-Cookie]=[JSESSIONID=Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5!1104478448!1625602300; path=/; HttpOnly] JSESSIONID 생성 규칙은 {세션 ID}!{Primary Server의 JDM IV}!{Secondary 서버의 JVM ID} 입니다. 그러므로 웹로직 서버가 클라이언트에게 만들어준 세션 ID는 Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5 임을 알 수 있습니다.(19). cookie_detail.jsp와 연결을 끊습니다.[debug] BaseProxy.cpp(3124): [client 192.168.56.1] weblogic: closeConn: pooling for &#39;192.168.56.2/12001&#39;[debug] BaseProxy.cpp(3138): [client 192.168.56.1] weblogic: closeConn: pooling &#39;0&#39;[debug] ap_proxy.cpp(705): [client 192.168.56.1] weblogic: request [/webapp/cookie_detail.jsp] processed successfully..................2.3 apache에 cookie-name을 TESTSESSION으로 변경하고 cookie_detail.jsp 요청 - 2회(1). 같은 클라이언트(브라우저)가 다시 똑같은 페이지를 요청할 경우 웹로직 첫번째 서버는 클라이언트의 HTTP 헤더에서 사용 가능한 JSESSIONID 쿠키를 발견합니다.[debug] ApacheProxy.cpp(1738): [client 192.168.56.1] weblogic: getPreferred: availcookie=[JSESSIONID=Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5!1104478448!1625602300] 이 JSESSIONID는 단계 1.2.(15)의 쿠키와 동일합니다. 현재 쿠키 내용을 보면, 세션 ID = Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5, Primary = 1104478448, Secondary = 1625602300 임을 알 수 있습니다.(2). 클라이언트는 Primary 서버로 연결되며, 쿠키로 TESTSESSION을 찾습니다. 하지만 Primary 서버와 클라이언트에는 TESTSESSION 쿠키가 없습니다. 웹로직 서버는 Primary 와 Secondary를 바꾸어 JSESSIONID 를 다시 할당합니다. 다시 할당 하는 이유는 다음 연결때는 Secondary로 가게 되기 때문입니다.[info] [client 192.168.56.1] weblogic: Header from WLS:[Set-Cookie]=[JSESSIONID=Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5!1104478448; path=/; HttpOnly][info] [client 192.168.56.1] weblogic: Hdrs to client (add):[Set-Cookie]=[JSESSIONID=Zf5gy86ROihZsEMgEvASu-t4kwc6pYRxcU3KnwIL27XuzW6dAoW5!1625602300!1104478448; path=/; HttpOnly] 웹로직에서 쿠키를 읽었을 때, Primary 값이 현재 서버가 아니면 is not primary server 등으로 로그를 뿌린다. 이때 다시 Primary 서버를 현재 서버로 정하고, Secondary 서버를 선택하게 되는데, 랜덤으로 선택한다. 원래 Secondary는 랜덤 선택.2.4 apache와 weblogic의 cookie name을 TESTSESSION으로 동일 설정(1). 첫 접속 시 웹로직은 TESTSESSION으로 쿠키를 할당합니다.(2). 두번째 접속 시 클라이언트가 요청하는 TESTSESSION은 웹로직과 동일하므로 쿠키를 발견하고, 파싱하여 정보를 얻을 수 있습니다.[debug] ApacheProxy.cpp(1738): [client 192.168.56.1] weblogic: getPreferred: availcookie=[TESTSESSION=Sfxh2Z5GFEaGKSt4fH_-YsWru2wFdHzmmZVJV1xwMwBQRT4Mp-EQ!1104478448!1625602300][debug] ApacheProxy.cpp(1785): [client 192.168.56.1] weblogic: Found cookie from cookie header: TESTSESSION=Sfxh2Z5GFEaGKSt4fH_-YsWru2wFdHzmmZVJV1xwMwBQRT4Mp-EQ!1104478448!1625602300[debug] BaseProxy.cpp(1464): [client 192.168.56.1] weblogic: Parsing cookie TESTSESSION=Sfxh2Z5GFEaGKSt4fH_-YsWru2wFdHzmmZVJV1xwMwBQRT4Mp-EQ!1104478448!1625602300(3). 쿠키에서 세션 타임아웃 방지를 위한 시간만 갱신합니다.[info] [client 192.168.56.1] weblogic: Hdrs to client (add):[Date]=[Mon, 06 Jul 2015 05:32:18 GMT]2.5 apache cookie name은 TESTSESSION2, wls cookie name은 TESTSESSION1 일 때 단계 1.2 의 테스트와 동일한 결과를 보여줍니다. 요청하는 쿠키명과 배급되는 쿠키명이 다르기 때문입니다.이로써 쿠키로 사용자(브라우저)가 신규 접속인지, 아니라면 가지고 있는 쿠키를 분석하여 웹 어플리케이션이 원하는 정보인지를 알 수 있습니다.3. JSESSION ID 테스트2.1 같은 cookie 를 발급하는 cookie_detail.jsp 호출 (1) webapp1/cookie_detail.jsp 호출 -&amp;gt; count = 1(2) webapp1/cookie_detail.jsp 호출 -&amp;gt; count = 2(3) webapp2/cookie_detail.jsp 호출 -&amp;gt; count = 1(4) webapp1/cookie_detail.jsp 호출 -&amp;gt; count = 1 webapp1과 webapp2가 동일한 쿠키명을 사용하고 있어, 다른 어플리케이션이 세션을 덮어씌워버리기 때문에 1씩 증가되는 count 변수 또한 초기화 됩니다.사용자의 세션 정보가 필요한 어플리케이션이 다수 일때, 어플리케이션들의 쿠키명이 동일하다면 이전의 정보가 제거 됩니다. 이를 위해 어플리케이션 별로 쿠키명이 달라야 합니다.4. 세션 공유 테스트4.1 도메인 단위여러 서브 도메인에서 하나의 어플리케이션 세션을 weblogic.xml 설정을 통해 공유 할 수 있습니다.&amp;lt;weblogic-web-app&amp;gt; &amp;lt;session-descriptor&amp;gt; &amp;lt;cookie-name&amp;gt;SUBSESSION&amp;lt;/cookie-name&amp;gt; &amp;lt;cookie-domain&amp;gt;.main.com&amp;lt;/cookie-domain&amp;gt; &amp;lt;/session-descriptor&amp;gt;&amp;lt;/weblogic-web-app&amp;gt;192.168.56.2 sub1.main.com sub2.main.com 위의 설정은 sub1.main.com과 sub2.main.com 에서 세션 공유가 됩니다. cookie-domain에는 도메인 명 외에도, ip주소(.168.56.2)로 설정하여 세션 공유할 수 있습니다. 점(.)이 최소 2개가 있어야 합니다. (.co.kr 은 되지 않습니다.)4.2 어플리케이션 단위여러 어플리케이션을 하나의 인스턴스에서 세션을 공유할 때는 ear 구조가 되어야 합니다.(1). ear 구조/earapp webapp1 (단계 3.1의 어플리케이션) webapp2 (단계 3.1의 어플리케이션) META-INF application.xml&amp;lt;application&amp;gt; &amp;lt;display-name&amp;gt;earapp&amp;lt;/display-name&amp;gt; &amp;lt;module&amp;gt; &amp;lt;web&amp;gt; &amp;lt;web-uri&amp;gt;webapp1&amp;lt;/web-uri&amp;gt; &amp;lt;context-root&amp;gt;/webapp1&amp;lt;/context-root&amp;gt; &amp;lt;/web&amp;gt; &amp;lt;/module&amp;gt;​ &amp;lt;module&amp;gt; &amp;lt;web&amp;gt; &amp;lt;web-uri&amp;gt;webapp2&amp;lt;/web-uri&amp;gt; &amp;lt;context-root&amp;gt;/webapp2&amp;lt;/context-root&amp;gt; &amp;lt;/web&amp;gt; &amp;lt;/module&amp;gt;&amp;lt;/application&amp;gt;&amp;lt;weblogic-application&amp;gt; &amp;lt;session-descriptor&amp;gt; &amp;lt;cookie-path&amp;gt;/&amp;lt;/cookie-path&amp;gt; &amp;lt;sharing-enabled&amp;gt;true&amp;lt;/sharing-enabled&amp;gt; &amp;lt;/session-descriptor&amp;gt;&amp;lt;/weblogic-application&amp;gt;ear패키징으로 인해 webapp1과 webapp2가 묶여있습니다.webapp1과 webapp2 둘다 생성하는 쿠키 이름은 JSESSIONID 입니다. 옵션으로 두 어플리케이션은 JSESSIONID를 공유합니다." }, { "title": "[WebLogic] Cluster간 Session Replication", "url": "/posts/weblogic_tip_5/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Cluster, Session, Replication", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. Session Replication 대상 3. Session Replication 조건 4. Instance Shutdown 시에 Primary와 Secondary Session 이동 5. 로컬에서 Replication Group 테스트 6. 로컬에서 Replication Group 테스트 - #21. 개요WebLogic Cluster 의 Session 복제 조건을 알아본다.2. Session Replication 대상 사용자가 was1번에 접속 시, 이를 Primary Server라 하며 Session을 생성. Primary Server에 생성된 Session Backup을 Secondary Server에 복제. Secondary Server는 같은 Cluster내 Member중 Random하게 하나를 선택. 말이 랜덤이지, 기준이 있다 (웹로직만의 기준). 아래 그림. Primary Server가 shutdown 되더라도, Secondary Server에 backup 본이 있음. -&amp;gt; Failover3. Session Replication 조건Session 생성은 HttpSession.setAttribute() method으로 실행됨.즉, 사용자의 Request가 있다고 Session Trigger(간단한 의미로 Session이 유효한지)등은 Page 새로고침(F5)만으로 발생하는 것이 아니라 해당 Page에 setAttribute()가 있어야 함.Primary Server의 shutdown이 되더라도, Secondary Server에 backup Session이 남아있지만,더이상 사용자의 Request로 인해 setAttribute()를 호출하지 않으면, 해당 Session은 Secondary Server에만 존재하지 Primary Server가 없는 상황이 발생.또한, 다음 표는 Cluster 내 Member들 간 Session 복제 우선 순위.1순위 - 다른 머신, 같은 그룹2순위 - 같은 머신, 같은 그룹3순위 - 같은 머신, 다른 그룹4순위 - 다른 머신, 다른 그룹머신은 이중화 장비를 의미. 그룹은 Console - Servers - - Configuration - Cluster에서 Replication Group으로 지정한다. 사실, 복잡한 시스템 또는 특별한 요구사항이 없다면 일반적으로 신경쓰지 않는다.4. Instance Shutdown 시에 Primary와 Secondary Session 이동m1에 Primary 2, Secondary 1m2에 Primary 1, Secondary 2m2 instance를 shutdown 시에,m1의 Secondary가 m1의 Primary로 이동한다.5. 로컬에서 Replication Group 테스트테스트 목적 : 클러스터링 세션의 Primary, Secondary 구성의 여러가지 테스트.환경 : Machine1과 Machine2 는 물리적으로 서버가 다르다.Machine1 에는 인스턴스 M1, M2 를 묶어 띄웠고,Machine2 에는 인스턴스 M3, M4 를 묶어 띄웠다.M1, M2, M3, M4 는 Clustering 되었다.===== WLS =========================AdminServer - 172.16.0.101—- Clustering —-Machine1 (M1, M2) - 172.16.0.101Machine2 (M3, M4) - 172.16.0.99-——————-===================================웹로직 기본 알고리즘에 의하면, 다음과 같이 클러스터링 순서가 정해짐.M1 - M3M2 - M4M3 - M1M4 - M2* 기동 순서에 따라 약간의 차이는 있지만, 대체로 조건표에 부합됨.Replication Group을 아래와 같이,M1 (Replication Group : M1) , (Preferred Secondary Group : M2)M2 (Replication Group : M2) , (Preferred Secondary Group : M1)M3 (Replication Group : M3) , (Preferred Secondary Group : M4)M4 (Replication Group : M4) , (Preferred Secondary Group : M3)주게 되면M1 - M2M2 - M1M3 - M4M4 - M3와 같이 설정이 강제로 된다.조건표 무시하고, 직접 선호도를 설정 가능.다만, 동시 기동하여야 선호하는 그룹으로 설정이 가능하다.* Replication Group : 나의 그룹명* Preferred Secondary Group : 선호하는 세컨드리 인스턴스의 그룹명6. 로컬에서 Replication Group 테스트 - #2위 테스트에서, Replication Group, Preferred Group 을 설정하여도기동 순서에 따라서, 원하지 않는 순서로 맺어지는 줄 알았는데..기동 할 때마다 조건에 부합되도록 클러스터 구성을 재조정 하고 있다.내가 설정한 조건대로라면,M1 - M2M2 - M1M3 - M4M4 - M3 으로 클러스터 Primary/Secondary 설정이 되어야 하는데이 기동순서를 조정하여 다음과 같이 조건에 맞지 않게 붙게 하였다.그림1. M1 , M3 인스턴스만 기동하여 서로 강제 클러스터링그림2. M2 인스턴스를 추가 기동하였더니, 클러스터 구조 재조정그림3. M4 인스턴스를 추가 기동하였더니, 클러스터 구조 재조정클러스터 구조가 재조정되며, 세션이 이동된다.상당히 무거운 시스템에서는 이러한 재조정 사태에 부하가 발생할 것 같은데..관련 내용은 오라클 문서에서 찾지 못했다." }, { "title": "[WebLogic] 웹로직에 부하를 주는 스레드 찾기(Linux, AIX, Windows7)", "url": "/posts/weblogic_tip_13/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. 다음의 JSP를 배포하여 실행 3. OS별 확인 방법 3.1 Linux 3.2 Windows 7 3.3 AIX 1. 개요웹로직에 부하를 주는 스레드 찾기(Linux, AIX, Windows7)2. 다음의 JSP를 배포하여 실행for (int i=0; i &amp;lt; 3; i++) { Thread x=new Thread(new Runnable(){ public void run() { System.out.println(&quot;Thread &quot; +Thread.currentThread().getName() + &quot; started&quot;); double val=10; for (;;) { Math.atan(Math.sqrt(Math.pow(val, 10))); } } }); x.start(); }%&amp;gt;3. OS별 확인 방법3.1 Linux# ps -ef | grep java instance PID를 찾는다. 찾은 PID: 22384# watch &quot;ps -eLo pid,ppid,tid,pcpu,comm | grep 22384&quot; watch 명령어로 2초마다 cpu 사용량을 게더링 할 수 있다. 문서에는 watch가 cpu 사용량을 게더링하기 유용하지 않은 명령어라고 한다.# ps -eLo pid,ppid,tid,pcpu,comm | grep 22384 &amp;gt; 22384.out 현재 cpu 사용량 게더링 결과를 22384.out으로 저장 한다.# cat 22384.out | awk &#39;{ print &quot;pccpu: &quot;$4&quot; pid: &quot;$1&quot; ppid: &quot;$2&quot; ttid: &quot;$3&quot; comm: &quot;$5}&#39; |sort -n 게더링 결과의 cpu 사용량을 기준으로 내림차순하여 본다.# ps -eLo pid,ppid,tid,pcpu,comm | grep 22384 | awk &#39;{ print &quot;pccpu: &quot;$4&quot; pid: &quot;$1&quot; ppid: &quot;$2&quot; ttid: &quot;$3&quot; comm: &quot;$5}&#39; |sort -n ‘다’와 ‘라’의 명령어를 한 줄로 합쳐서 볼 수 있다. 실행 결과는 다음과 같다. 인스턴스(22384)의 32.2퍼센트 cpu를 사용하는 스레드 아이디는 22557, 22558, 22559 22557, 22558, 22559를 헥사값(16진수)로 변환하면 각각 0x581d, 0x581e, 0x581f 다.# kill -3 22384 덤프를 생성 후, 위에서 구한 헥사값을 검색하면 다음과 같다. jsp에서 Thread 3개를 생성 하고, 각각 Math.atan 메소드 실행 부분을 덤프에서도 확인할 수 있다.&quot;Thread-36&quot; daemon prio=10 tid=0x00007f43d0059800 nid=0x581f runnable [0x00007f43cf8f7000] java.lang.Thread.State: RUNNABLE at java.lang.StrictMath.atan(Native Method) at java.lang.Math.atan(Math.java:204) at jsp_servlet.__highcpu$1.run(__highcpu.java:84) at java.lang.Thread.run(Thread.java:745) &quot;Thread-35&quot; daemon prio=10 tid=0x00007f43d0058800 nid=0x581e runnable [0x00007f43cf9f8000] java.lang.Thread.State: RUNNABLE at java.lang.StrictMath.atan(Native Method) at java.lang.Math.atan(Math.java:204) at jsp_servlet.__highcpu$1.run(__highcpu.java:84) at java.lang.Thread.run(Thread.java:745)&quot;Thread-34&quot; daemon prio=10 tid=0x00007f43d005b800 nid=0x581d runnable [0x00007f43cfaf9000] java.lang.Thread.State: RUNNABLE at java.lang.StrictMath.atan(Native Method) at java.lang.Math.atan(Math.java:204) at jsp_servlet.__highcpu$1.run(__highcpu.java:84) at java.lang.Thread.run(Thread.java:745)3.2 Windows 7여기 에서 프로세스 리스트를 확인할 수 있는 pslist 툴을 설치한다. 압축을 해제하고 cmd로 해당 디렉토리에서 다음 작업을 이어간다.# pslist java pc에서 현재 동작중인 프로세스 중 자바를 찾아본다. java PID는 7820 각 파라메타 설명은 pslist 툴을 다운로드 받은 홈페이지에 있다.# pslist -d 78208604 8 138786 Running 0:03:25.999 0:00:00.000 0:03:30.540 java 프로세스의 스레드 정보를 볼 수 있다. 다음이 그 정보인데, Cswtch와 User/Kernel Time을 보면 문제가 되는 스레드 아이디는 7384, 5712, 8604 다.Cswtch(Context Switch)는 멀티태스킹을 위하여 실행되는 여러 스레드들의 상태를 저장하고, 복구하는 일련의 과정이 얼마나 자주 일어났는지를 뜻한다. 참고사이트: http://en.wikipedia.org/wiki/Context_switch User Time은 CPU의 사용자 영역에서 실행된 총 시간이다. 모두 03분 26초 실행 시간을 보여주고 있다. Kernel Time은 CPU의 커널 영역을 의미하는 시간이다. User Time 3분대를 기록한 스레드 3개가 너무 오랫동안 실행이 되며, Cswtch 수치가 이상하다. 각 스레드 아이디를 헥사값으로 변환하여 스레드 덤프에서 찾아보자. 7384: 1CD8, 5712: 1650, 8604: 219C 각각을 찾아보니 다음과 같다.&quot;Thread-15&quot; daemon prio=6 tid=0x0000000007729800 nid=0x219c runnable [0x000000000cdaf000] java.lang.Thread.State: RUNNABLE at java.lang.StrictMath.atan(Native Method) at java.lang.Math.atan(Math.java:187) at jsp_servlet.__highcpu$1.run(__highcpu.java:79) at java.lang.Thread.run(Thread.java:662)&quot;Thread-14&quot; daemon prio=6 tid=0x0000000007729000 nid=0x1650 runnable [0x000000000ccaf000] java.lang.Thread.State: RUNNABLE at java.lang.StrictMath.atan(Native Method) at java.lang.Math.atan(Math.java:187) at jsp_servlet.__highcpu$1.run(__highcpu.java:79) at java.lang.Thread.run(Thread.java:662)&quot;Thread-13&quot; daemon prio=6 tid=0x0000000007728000 nid=0x1cd8 runnable [0x000000000cbaf000] java.lang.Thread.State: RUNNABLE at java.lang.StrictMath.atan(Native Method) at java.lang.Math.atan(Math.java:187) at jsp_servlet.__highcpu$1.run(__highcpu.java:79) at java.lang.Thread.run(Thread.java:662)3.3 AIX# ps -ef | grep java instance PID를 찾는다. 찾은 PID: 16908684# ps -mp 16908684 -o THREAD instance PID의 스레드 목록을 출력한다. USER PID PPID TID S CP PRI SC WCHAN F TT BND COMMAND cs2 16908684 17825820 - A 360 60 55 * 202001 pts/2 - /usr/java7_64/bin/java -Xms512m -Xmx512m -Dweblo - - - 4980787 S 0 82 1 f1000f0a10004c40 8410400 - - - - - - 9306279 S 0 82 1 f1000f0a10008e40 8410400 - - - - - - 12976337 Z 0 82 1 - c00001 - - - - - - 13893815 S 0 82 1 f1000f0a1000d440 8410400 - - - - - - 15663295 Z 0 98 1 - c00001 - - - - - - 20578311 S 0 82 1 f1000f0a10013a40 8410400 - - - - - - 21168367 S 0 60 1 f1000f0a10014340 8410400 - - - - - - 21561529 R 120 162 0 - 400000 - - - - - - 24510581 S 0 66 1 f10005000e3ba208 410400 - - - - - - 31195139 Z 0 98 1 - c00001 - - - - - - 32243767 S 0 82 1 f1000f0a1001ec40 8410400 - - - - - - 38928587 S 0 82 1 f100012020bbd4b0 410400 - - - - - - 39583921 S 0 82 1 f100012027555f78 410400 - - - - - - 46858399 S 0 82 1 f1000f0a1002cb40 8410400 - - - - - - 52035835 S 0 100 1 f1000f0a10031a40 8410400 - - - - - - 53542927 S 0 82 1 f1000f0a10033140 8410400 - - - - - - 54525969 S 0 60 1 f1000f0a10034040 8410400 - - - - - - 56295463 Z 0 98 1 - c00001 - - - - - - 56819751 Z 0 98 1 - c00001 - - - - - - 56885315 S 0 82 1 f1000f0a10036440 8410400 - - - - - - 60031145 S 0 82 1 f1000f0a10039440 8410400 - - - - - - 68812921 S 0 82 1 f1000f0a10041a40 8410400 - - - - - - 70451297 S 0 82 1 f1000f0a10043340 8410400 - - - - - - 72417493 Z 0 98 1 - c00001 - - - - - - 73072781 S 0 94 1 f1000f0a10045b40 8410400 - - - - - - 76677207 Z 0 98 1 - c00001 - - - - - - 77267163 S 0 82 1 f100012020b6ec78 410400 - - - - - - 77594839 S 0 60 1 f1000f0a1004a040 8410400 - - - - - - 85590073 S 0 82 1 f1000f0a10051a40 8410400 - - - - - - 90570909 S 0 82 1 f1000f0a10056640 8410400 - - - - - - 95551739 S 0 82 1 f1000f0a1005b240 8410400 - - - - - - 99811459 S 0 78 1 f1000f0a1005f340 8410400 - - - - - - 103415911 S 0 82 1 f1000f0a10062a40 8410400 - - - - - - 103546957 S 0 82 1 f100012020b6eb78 410400 - - - - - - 111018063 S 0 60 1 f1000120085fc598 410400 - - - - - - 118685867 S 0 66 1 f1000f0a10071340 8410400 - - - - - - 18088333 S 0 78 1 f1000f0a10091440 8410400 - - - - - - 18153845 S 0 60 1 f1000f0a10091540 8410400 - - - - - - 18612571 S 0 82 1 f1000f0a10091c40 8410400 - - - - - - 22413601 S 0 82 1 f1000f0a10095640 8410400 - - - - - - 23527931 Z 0 98 1 - c00001 - - - - - - 43450815 R 120 162 0 - 400000 - - - - - - 58196403 S 0 82 1 f1000f0a100b7840 8410400 - - - - - - 61538703 S 0 78 1 f1000f0a100bab40 8410400 - - - - - - 66978283 S 0 82 1 f1000f0a100bfe40 8410400 - - - - - - 76087735 S 0 82 1 f1000f0a100c8940 8410400 - - - - - - 79102281 S 0 60 1 f1000f0a100cb740 8410400 - - - - - - 83231169 S 0 82 1 f10001201fb6a978 410400 - - - - - - 83624307 S 0 82 1 f1000f0a100cfc40 8410400 - - - - - - 83755267 S 0 62 1 f100011808232118 410400 - - - - - - 84541707 R 120 162 0 - 400000 - - - - - - 85000601 S 0 66 1 f1000f0a100d1140 8410400 - - - - - - 91291923 S 0 82 1 f1000f0a100d7140 8410400 - - - - - - 94175563 S 0 82 1 f1000f0a100d9d40 8410400 - - - - - - 95551785 Z 0 98 1 - c00001 - - - - - - 96010609 S 0 82 1 f1000f0a100db940 8410400 - - - - - - 97386857 S 0 82 1 f1000f0a100dce40 8410400 - - - - - - 101187847 S 0 60 1 f1000f0a100e0840 8410400 - - - CP는 ~ 이다. 대부분 CP가 0이지만 TID(Thread ID) 21561529, 43450815, 84541707는 120의 높은 값을 보여주고 있다. 위 TID를 각각 16진수로 변환하면 14900B9, 29701BF, 50A010B가 된다. 스레드 덤프에서 16진수로 변환한 TID를 검색해보니, 실행한 jsp 정보를 볼 수 있었다.3XMTHREADINFO &quot;Thread-33&quot; J9VMThread:0x00000000524AEB00, j9thread_t:0x00000100151EC5C0, java/lang/Thread:0x00000000498A4898, state:R, prio=53XMJAVALTHREAD (java/lang/Thread getId:0x54, isDaemon:true)3XMTHREADINFO1 (native thread ID:0x14900B9, native priority:0x5, native policy:UNKNOWN, vmstate:CW, vm thread flags:0x00000001)3XMCPUTIME CPU usage total: 2274.685427000 secs, user: 2274.684771000 secs, system: 0.000656000 secs3XMHEAPALLOC Heap bytes allocated since last GC cycle=0 (0x0)3XMTHREADINFO3 Java callstack:4XESTACKTRACE at jsp_servlet/__test$1.run(__test.java:81(Compiled Code))4XESTACKTRACE at java/lang/Thread.run(Thread.java:795)3XMTHREADINFO3 Native callstack:4XENATIVESTACK _event_wait+0x2b8 (0x09000000005C489C [libpthreads.a+0x1689c])4XENATIVESTACK _cond_wait_local+0x4e4 (0x09000000005D2668 [libpthreads.a+0x24668])4XENATIVESTACK _cond_wait+0xbc (0x09000000005D2C40 [libpthreads.a+0x24c40])4XENATIVESTACK pthread_cond_wait+0x1a8 (0x09000000005D38AC [libpthreads.a+0x258ac])4XENATIVESTACK (0x090000000149D2F4 [libj9thr26.so+0x62f4])4XENATIVESTACK (0x090000000149CF40 [libj9thr26.so+0x5f40])4XENATIVESTACK (0x09000000013E2F58 [libj9vm26.so+0xff58])4XENATIVESTACK (0x09000000013EF850 [libj9vm26.so+0x1c850])4XENATIVESTACK (0x0900000001DCEF3C [libj9jit26.so+0x7dff3c])4XENATIVESTACK (0x09000000013D9864 [libj9vm26.so+0x6864])4XENATIVESTACK (0x09000000014B4CE0 [libj9prt26.so+0x2ce0])4XENATIVESTACK (0x09000000013D96D4 [libj9vm26.so+0x66d4])4XENATIVESTACK (0x0900000001499AF4 [libj9thr26.so+0x2af4])4XENATIVESTACK _pthread_body+0xf0 (0x09000000005B1D54 [libpthreads.a+0x3d54])NULL​3XMTHREADINFO &quot;Thread-35&quot; J9VMThread:0x00000000524B1300, j9thread_t:0x000001001771AD40, java/lang/Thread:0x00000000498A5908, state:R, prio=53XMJAVALTHREAD (java/lang/Thread getId:0x56, isDaemon:true)3XMTHREADINFO1 (native thread ID:0x29701BF, native priority:0x5, native policy:UNKNOWN, vmstate:CW, vm thread flags:0x00000001)3XMCPUTIME CPU usage total: 2265.056957000 secs, user: 2265.056386000 secs, system: 0.000571000 secs3XMHEAPALLOC Heap bytes allocated since last GC cycle=0 (0x0)3XMTHREADINFO3 Java callstack:4XESTACKTRACE at jsp_servlet/__test$1.run(__test.java:81(Compiled Code))4XESTACKTRACE at java/lang/Thread.run(Thread.java:795)3XMTHREADINFO3 Native callstack:4XENATIVESTACK _event_wait+0x2b8 (0x09000000005C489C [libpthreads.a+0x1689c])4XENATIVESTACK _cond_wait_local+0x4e4 (0x09000000005D2668 [libpthreads.a+0x24668])4XENATIVESTACK _cond_wait+0xbc (0x09000000005D2C40 [libpthreads.a+0x24c40])4XENATIVESTACK pthread_cond_wait+0x1a8 (0x09000000005D38AC [libpthreads.a+0x258ac])4XENATIVESTACK (0x090000000149D2F4 [libj9thr26.so+0x62f4])4XENATIVESTACK (0x090000000149CF40 [libj9thr26.so+0x5f40])4XENATIVESTACK (0x09000000013E2F58 [libj9vm26.so+0xff58])4XENATIVESTACK (0x09000000013EF850 [libj9vm26.so+0x1c850])4XENATIVESTACK (0x0900000001DCEF3C [libj9jit26.so+0x7dff3c])4XENATIVESTACK (0x09000000013D9864 [libj9vm26.so+0x6864])4XENATIVESTACK (0x09000000014B4CE0 [libj9prt26.so+0x2ce0])4XENATIVESTACK (0x09000000013D96D4 [libj9vm26.so+0x66d4])4XENATIVESTACK (0x0900000001499AF4 [libj9thr26.so+0x2af4])4XENATIVESTACK _pthread_body+0xf0 (0x09000000005B1D54 [libpthreads.a+0x3d54])NULL​3XMTHREADINFO &quot;Thread-34&quot; J9VMThread:0x0000000052308300, j9thread_t:0x000001001771B260, java/lang/Thread:0x00000000498A5250, state:R, prio=53XMJAVALTHREAD (java/lang/Thread getId:0x55, isDaemon:true)3XMTHREADINFO1 (native thread ID:0x50A010B, native priority:0x5, native policy:UNKNOWN, vmstate:CW, vm thread flags:0x00000001)3XMCPUTIME CPU usage total: 2264.278773000 secs, user: 2264.278270000 secs, system: 0.000503000 secs3XMHEAPALLOC Heap bytes allocated since last GC cycle=0 (0x0)3XMTHREADINFO3 Java callstack:4XESTACKTRACE at jsp_servlet/__test$1.run(__test.java:81(Compiled Code))4XESTACKTRACE at java/lang/Thread.run(Thread.java:795)3XMTHREADINFO3 Native callstack:4XENATIVESTACK _event_wait+0x2b8 (0x09000000005C489C [libpthreads.a+0x1689c])4XENATIVESTACK _cond_wait_local+0x4e4 (0x09000000005D2668 [libpthreads.a+0x24668])4XENATIVESTACK _cond_wait+0xbc (0x09000000005D2C40 [libpthreads.a+0x24c40])4XENATIVESTACK pthread_cond_wait+0x1a8 (0x09000000005D38AC [libpthreads.a+0x258ac])4XENATIVESTACK (0x090000000149D2F4 [libj9thr26.so+0x62f4])4XENATIVESTACK (0x090000000149CF40 [libj9thr26.so+0x5f40])4XENATIVESTACK (0x09000000013E2F58 [libj9vm26.so+0xff58])4XENATIVESTACK (0x09000000013EF850 [libj9vm26.so+0x1c850])4XENATIVESTACK (0x0900000001DCEF3C [libj9jit26.so+0x7dff3c])4XENATIVESTACK (0x09000000013D9864 [libj9vm26.so+0x6864])4XENATIVESTACK (0x09000000014B4CE0 [libj9prt26.so+0x2ce0])4XENATIVESTACK (0x09000000013D96D4 [libj9vm26.so+0x66d4])4XENATIVESTACK (0x0900000001499AF4 [libj9thr26.so+0x2af4])4XENATIVESTACK _pthread_body+0xf0 (0x09000000005B1D54 [libpthreads.a+0x3d54])NULL" }, { "title": "[WebLogic] 데이터소스 커넥션 풀 시도 횟수 관련 옵션", "url": "/posts/weblogic_tip_12/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Datasource, Connection Pool", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. 설명1. 개요데이터소스 커넥션 풀 시도 횟수 관련 옵션2. 설명Connection Reserve Timeout 기본값 10초.사진상 3 초일 경우,Reached maximum data… 에러의 경우3초 동안 Free connection pool 찾음.없으면 503 error.해당 3초 내에 몇번의 요청을 하는 구조인지는 모르겠다." }, { "title": "[WebLogic] weblogic.jar와 wlfullclient.jar", "url": "/posts/weblogic_tip_11/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. 설명1. 개요weblogic.jar와 wlfullclient.jar 생성 방법2. 설명WebLogic 10.0 이전까지는, weblogic.jar file 하나로 T3, WLS-IIOP client application을 개발하여 WebLogic Server과 통신할 수 있다.WebLogic 10.3.x 이후부터는, weblogic.jar 대신에 wlfullclient.jar을 사용해야 client application을 개발하고 사용할 수 있다.여기 에서 client application 확인여기 에서 wlfullclient.jar 생성 방법 확인 원격으로 PC에서 웹로직 서버 도메인 접근하여 어떠한 기능을 수행하려는 경우 wlfullclient.jar를 만들면 된다~" }, { "title": "[WebLogic] Session을 생성하고 복제하는 Method (setAttribute, getAttribute, getSession)", "url": "/posts/weblogic_tip_10/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Session", "date": "2021-12-20 19:31:57 +0900", "snippet": "Contents 1. 개요 2. Oracle 공식 문서 확인 3. 실제 Test 결과 및 결론1. 개요Session을 생성하고 복제하는 Method (setAttribute, getAttribute, getSession)2. Oracle 공식 문서 확인여기 에서 Session Replocation Sync가 setAttribute method로 동작한다는 부분은 다음과 같습니다. (setAttribute 로 검색시)3. 실제 Test 결과 및 결론Session 생성과 복제는, setAttribute, getAttribute method로 동작함을 확인하였습니다만.실제론, FailoverTest_get.jsp를 다음 처럼 수정하니, getSession(true)으로 Session 생성/복제가 동작됨을 확인했습니다.&amp;lt;% // Session session = request.getSession(true);%&amp;gt;Current Connected Server: &amp;lt;h3&amp;gt;&amp;lt;%=serverName%&amp;gt;&amp;lt;/h3&amp;gt; setAttribute()와 getAttribute()는 javax.servlet.ServletRequest class에 구현되어 있습니다. getSession()은 javax.servlet.http class에 구현되어 있으며, javax.servlet.ServletRequest를 상속 받습니다. (public interface HttpServletRequest extends ServletRequest)여기 문서의 문서의 getSession() 설명입니다.getSession(), getSession(true) = HttpSession이 존재하면 현재 HttpSession을 반환하고 존재하지 않으면 새로이 세션을 생성합니다.getSession(false) = HttpSession이 존재하면 현재 HttpSession을 반환하고 존재하지 않으면 새로이 생성하지 않고 그냥 null을 반환합니다." }, { "title": "[RHCSA] Container 생성", "url": "/posts/rhcsa_container/", "categories": "Study, RHCSA", "tags": "Study, RHCSA", "date": "2021-12-20 14:18:35 +0900", "snippet": "Contents 1. 개요 2. 컨테이너 생성 2.1 이미지 검색 2.2 이미지 다운로드 2.3 컨테이너 실행 3. 비-루트 계정 서비스 등록1. 개요podman 을 이용한 Container 생성과 비-루트 계정으로 서비스를 등록해본다.2. 컨테이너 생성2.1 이미지 검색# podman search docker.io/httpdINDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/library/httpd The Apache HTTP Server Project 3802 [OK]docker.io docker.io/centos/httpd-24-centos7 Platform for running Apache httpd 2.4 or bui... 40docker.io docker.io/manageiq/httpd Container with httpd, built on CentOS for Ma... 1 [OK]docker.io docker.io/clearlinux/httpd httpd HyperText Transfer Protocol (HTTP) ser... 1... skip ... 사용할(띄울) 이미지를 검색한다. 여기서는 httpd 에서 가장 낮은 버전(아무거나) 을 활용한다.# skopeo inspect docker://docker.io/library/httpd{ &quot;Name&quot;: &quot;docker.io/library/httpd&quot;, &quot;Digest&quot;: &quot;sha256:0c8dd1d9f90f0da8a29a25dcc092aed76b09a1c9e5e6e93c8db3903c8ce6ef29&quot;, &quot;RepoTags&quot;: [ &quot;2&quot;, &quot;2-alpine&quot;, &quot;2-alpine3.13&quot;, &quot;2-alpine3.14&quot;, &quot;2-alpine3.15&quot;, &quot;2-bullseye&quot;, &quot;2-buster&quot;,... skip ... inspect 명령을 사용하여 찾은 이미지에서 포함된 릴리즈들을 모두 확인할 수 있다. 우리는 2-alpine3.15 를 아래에서 사용하기로 하자.2.2 이미지 다운로드# podman pull docker.io/library/httpd:&quot;2-alpine3.14&quot;2.3 컨테이너 실행# mkdir /html# echo &quot;Hello World&quot; &amp;gt; /html/index.html 옵션으로, 호스트 디렉토리를 컨테이너에게 전달하기 위한 환경# podman run --detach --name &quot;myweb&quot; -p &quot;8080:80&quot; -v &quot;/html:/usr/local/apache2/htdocs:Z&quot; -e &quot;BLOGGER=DHKIM&quot; -e &quot;GIT=dhkim900331&quot; docker.io/library/httpd _–detach : 백그라운드 실행 –name : 컨테이너 명 -p : 호스트 8080 port를 컨테이너 80 port로 forwarding -v : 호스트 /html 디렉토리를 컨테이너의 /usr/…/htdocs 디렉토리로 연결 _ ㄴ Z 옵션은 SELinux 옵션. 주지 않으면 SELinux policy 다를 경우 권한 문제 발생_ _-e : 환경 변수를 key:value pair로 전달__ 마지막 argument는 아까 받은 이미지# podman ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3c6ad1ea13e3 docker.io/library/httpd:latest httpd-foreground 3 minutes ago Up 3 minutes ago 0.0.0.0:8080-&amp;gt;80/tcp myweb 컨테이너 실행 중인 상태(STATUS를 보고 판단)# podman exec -it myweb /bin/bashroot@3c6ad1ea13e3:/usr/local/apache2# hostname3c6ad1ea13e3 컨테이너 내부로 접속하여 hostname 명령을 쳐보았다.3. 비-루트 계정 서비스 등록 여기서부터는 비-루트 계정으로 로그인하면서 진행한다. 앞서 컨테이너 생성 시 아래에서 사용할 계정과 다르면 컨테이너를 지우고 여기 계정으로 다시 생성한다. systemctl –user 옵션을 사용한다. 반드시 ssh @ 방식으로 로그인 해야한다. 그렇지 않으면 다음 처럼 bus에 연결하지 못한다. # systemctl --userFailed to connect to bus: 그런 파일이나 디렉터리가 없습니다 # ssh test@localhost 컨테이너를 일반계정 test 에 서비스 등록하기 위하여 ssh 로그인# mkdir -p ~/.config/systemd/user# podman generate systemd myweb --new &amp;gt; ~/.config/systemd/user/container-myweb.service 현재 실행중인 myweb 컨테이너를 service 파일로 생성# podman stop myweb# podman rm myweb# systemctl --user enable --now container-myweb.service myweb 컨테이너를 정지/삭제 하고, user 서비스를 재부팅 시 자동 시작되도록 및 지금 당장 시작하도록 설정한다." }, { "title": "[RHCSA] Root Password 변경", "url": "/posts/rhcsa_resetpass/", "categories": "Study, RHCSA", "tags": "Study, RHCSA", "date": "2021-12-16 15:55:18 +0900", "snippet": "Contents 1. 개요 2. 설명1. 개요root 계정 패스워드 변경 방법2. 설명(1). Linux 부팅 단계에서 e 를 눌러 명령줄 편집모드 진입(2). linux 행에 마지막(End 키)에 rd.break 입력 후 Ctrl-x 키로 이어서 부팅 일반 파일 시스템의 루트가 올라오지 않아, sysroot가 올라온다. 그래서 아래에서 _chroot /sysroot_를 한다고 구글신이 알려준다.(3). sysroot 리마운트현재 sysroot가 ro(read only)다.리마운트 한다.# mount -o(options) remount,rw /sysroot다음 명령어가 정확히 어떤 의미인지 모르나, 시스템 파일이 있는 root로 변경하는 것으로 보인다.# chroot /sysroot(4). root 패스워드 변경# passwd rootNew Password:Re-type Password:(5). autorelabel변경 완료 후 부팅 시에 SELinux가 /etc/shadow 파일을 리라벨링(?) 하도록 지시한다.# touch /.autorelabel(6). reboot# exit# exit 두번의 exit을 통해 reboot 시도한다.(7). relabel 작업으로 보여지는 로그들" }, { "title": "[RHCSA] NFS 마운트", "url": "/posts/rhcsa_nfs_1/", "categories": "Study, RHCSA", "tags": "Study, RHCSA", "date": "2021-12-16 15:55:18 +0900", "snippet": "Contents 1. 개요 2. 테스트 환경 준비 2.1 NFS 서버 환경 2.2 NFS 클라이언트 환경 3. NFS 마운트 3.1 mount 명령줄 3.2 /etc/fstab 3.3 autofs (1). 직접맵 (2). 간접맵 1. 개요NFS 환경에서 마운트 방법을 알아본다. 명령줄 mount (리붓시 날라감) /etc/fstab 파일 (영구 적용) autofs (반영구 적용으로 인한 자원 효율적 사용, 동적으로 자동 마운트. 권장)2. 테스트 환경 준비RHCSA 실습으로 주어진 랩 환경에서 하다가, 본인 로컬 VM에서 바로 하려니까 기본 환경을 준비하지 않아 안되었던 부분이 있었다.2.1 NFS 서버 환경# yum install -y nfs-utils# systemctl enable --now nfs-server.service 대부분 기본으로 설치되어 있는 nfs 패키지를 설치하고, nfs-server 서비스 실행# mkdir -p /public_NAS/{admin,manager,employee}# tree /public_NAS/public_NAS├── admin├── employee└── manager /public_NAS 에 admin, manager, employee 디렉토리 생성# echo &quot;/public_NAS *(rw)&quot; &amp;gt;&amp;gt; /etc/exports# exportfs -r exports 파일에 NFS 서버가 공유할 디렉토리 설정# firewall-cmd --add-service=nfs --permanent# firewall-cmd --reload nfs 방화벽 허용 정책# exportfs -v# showmount -e &amp;lt;NFS Server ip&amp;gt;Export list for servera:/public_NAS * exportfs -v : exportfs 파일 정상 등록 여부 확인 showmount -e : NFS Server에서 공유하는 디렉토리 리스트 확인2.2 NFS 클라이언트 환경# yum install -y nfs-utils# systemctl enable --now nfs-client.service RHEL8은 기본적으로 nfs-client 서비스는 자동 시작 되어 있다.# showmount -e &amp;lt;NFS Server ip&amp;gt;Export list for servera:/public_NAS * client 에서 NFS Server로 조회 결과가 좋다.3. NFS 마운트3.1 mount 명령줄# mkdir /shares# mount -t nfs4 &amp;lt;NFS Server ip&amp;gt;:/public_NAS /shares# mount | grep nfs4x.x.x.x:/public_NAS on /shares type nfs4 (rw,relatime,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=x.x.x.x,local_lock=none,addr=x.x.x.x)# tree /shares/shares├── admin├── employee└── manager mount가 쉽게 잘 되었다. 재기동하면 날라간다~아래 다른 방법을 테스트하기 위해서는…# cd /tmp# umount /shares3.2 /etc/fstab# echo &quot;&amp;lt;NFS Server ip&amp;gt;:/public_NAS /shares nfs4 defaults,rw,sync 0 0&quot; &amp;gt;&amp;gt; /etc/fstab# systemctl daemon-reload# mount /shares rw는 기본 옵션이다. sync옵션은 그냥 갑자기 넣었다. 이렇게 옵션을 넣을 수 있다고 양식을 보여주기 위함.3.3 autofs# yum install -y autofs(1). 직접맵# echo &quot;/- /etc/directMap&quot; &amp;gt;&amp;gt; /etc/auto.master.d/shares.autofs /- : 해당 문자 자체가 직접 맵. NFS Server와 디렉토리를 일대일(1:1)로 연결한다는 뜻.# echo &quot;/local/admin -rw,sync,fstype=nfs4 &amp;lt;NFS Server ip&amp;gt;:/public_NAS/admin&quot; &amp;gt; /etc/directMap# systemctl enable --now autofs /local/admin : 해당 디렉토리는 만들지 않는다. autofs 가 자동 생성한다.(2). 간접맵# echo &quot;/locals /etc/indirectMap&quot; &amp;gt;&amp;gt; /etc/auto.master.d/shares.autofs /locals 디렉토리를 간접맵으로 연결 한다. 간접맵과 달리 일대일이 아니라, 다수의 디렉토리를 자동으로 마_운트 한다.# echo &quot;* -rw,sync,fstype=nfs4 &amp;lt;NFS Server ip&amp;gt;:/public_NAS/&amp;amp;&quot; &amp;gt; /etc/indirectMap /locals 디렉토리에서 요청하는 디렉토리(*)를 /public_NAS/ 아래에서(&amp;amp;) 가져온다.# ll /locals/{admin,manager,employee}/locals/admin:합계 0/locals/employee:합계 0/locals/manager:합계 0 /locals 디렉토리를 만들지 않았고, autofs 를 재실행 하지 않고도 자동 마운트 되었다. 다만 디렉토리명을 정확히 알아야만 접근 및 자동 마운트가 된다.# mount | grep /locals/etc/indirectMap on /locals type autofs (rw,relatime,fd=26,pgrp=32434,timeout=300,minproto=5,maxproto=5,indirect,pipe_ino=77703)&amp;lt;NFS Server ip&amp;gt;:/public_NAS/admin on /locals/admin type nfs4 (rw,relatime,sync,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.16,local_lock=none,addr=&amp;lt;NFS Server ip&amp;gt;)&amp;lt;NFS Server ip&amp;gt;:/public_NAS/manager on /locals/manager type nfs4 (rw,relatime,sync,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.16,local_lock=none,addr=&amp;lt;NFS Server ip&amp;gt;)&amp;lt;NFS Server ip&amp;gt;:/public_NAS/employee on /locals/employee type nfs4 (rw,relatime,sync,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.16,local_lock=none,addr=&amp;lt;NFS Server ip&amp;gt;)" }, { "title": "[RHCSA] LVM 확장", "url": "/posts/rhcsa_lvm_2/", "categories": "Study, RHCSA", "tags": "Study, RHCSA", "date": "2021-12-16 15:55:18 +0900", "snippet": "Contents 1. 개요 2. 설명 2.1 현재 상황 2.2 볼륨 그룹 확장과 추가 파티셔닝 2.3 논리 볼륨 확장 1. 개요특정 마운트 지점의 공간이 부족하다는 가정하에확장 방법을 알아본다.2. 설명2.1 현재 상황# df -h /dataFilesystem Size Used Avail Use% Mounted on/dev/mapper/servera_01_vg-servera_01_lv 395M 24M 372M 6% /data /data Total Size가 395MB 이다.# mount | grep /data/dev/mapper/servera_01_vg-servera_01_lv on /data type xfs (rw,relatime,seclabel,attr2,inode64,noquota) /dev/mapper/servera_01_vg-servera_01_lv 장치명도 확인을 하였다. 이 부분은 그냥 쳐본거지, 여기서 얻어야만 하는 정보는 없다./data 의 총 크기를 최소 700MB로 만들기 위해서는 대략 400MB를 추가 할당해주어야 한다.2.2 볼륨 그룹 확장과 추가 파티셔닝# lvdisplay --- Logical volume --- LV Path /dev/servera_01_vg/servera_01_lv LV Name servera_01_lv VG Name servera_01_vg LV UUID SKBNR5-5EJc-k2U1-B5tB-hC6y-Je6W-myzhUV LV Write Access read/write LV Creation host, time servera.lab.example.com, 2021-12-09 00:24:30 -0500 LV Status available # open 1 LV Size 400.00 MiB Current LE 100 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 /data 가 마운트된 장치의 논리볼륨(LV)은 servera_01_vg 볼륨 그룹에서 할당되었다.# vgdisplay servera_01_vg --- Volume group --- VG Name servera_01_vg System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 2 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 2 Act PV 2 VG Size 504.00 MiB PE Size 4.00 MiB Total PE 126 Alloc PE / Size 100 / 400.00 MiB Free PE / Size 26 / 104.00 MiB VG UUID sNogVl-KWL2-F4UZ-C3s6-KJaj-LPrV-zVwGEr 해당 볼륨 그룹의 정보. Free Size가 104MB이므로 300MB 정도를 더 확장해야 한다. 여기 Free Size가 충분했다면 볼륨 그룹 확장이 필요 없다.# parted /dev/vdb print Model: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 269MB 268MB primary lvm 2 271MB 539MB 268MB primary lvm 디스크 장치 크기는 5369MB로 여유가 있다.# parted /dev/vdb mkpart primary 540MB 900MB# parted /dev/vdb set 3 lvm on# udevadm settle 추가로 파티션을 생성하엿다.# parted /dev/vdb print Model: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 269MB 268MB primary lvm 2 271MB 539MB 268MB primary lvm 3 540MB 900MB 360MB primary lvm# pvcreate /dev/vdb3# vgextend servera_01_vg /dev/vdb3 /dev/vdb3 장치를 볼륨으로 만들고, 기존 servera_01_vg 그룹에 할당하였다.# vgdisplay --- Volume group --- VG Name servera_01_vg System ID Format lvm2 Metadata Areas 3 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 3 Act PV 3 VG Size 844.00 MiB PE Size 4.00 MiB Total PE 211 Alloc PE / Size 100 / 400.00 MiB Free PE / Size 111 / 444.00 MiB VG UUID sNogVl-KWL2-F4UZ-C3s6-KJaj-LPrV-zVwGEr Free Size가 444 MB로 크게 늘어났다.2.3 논리 볼륨 확장# lvextend -L 700MB -n /dev/servera_01_vg/servera_01_lv _700MB_는 추가할 사이즈가 아니라, 최종 사이즈다. 명령어로 가상 디스크 장치(LV)를 확장한다.# xfs_growfs /data 해당 명령어로 새롭게 늘어난 비어있는 공간을 xfs로 채워넣는다. ext4 의 경우에는 resize2fs 를 사용한다.# df -h /dataFilesystem Size Used Avail Use% Mounted on/dev/mapper/servera_01_vg-servera_01_lv 695M 26M 670M 4% /data 695MB로 많이 늘어났다~~" }, { "title": "[RHCSA] LVM 생성", "url": "/posts/rhcsa_lvm_1/", "categories": "Study, RHCSA", "tags": "Study, RHCSA", "date": "2021-12-16 15:55:18 +0900", "snippet": "Contents 1. 개요 2. 디스크 초기화 및 파티셔닝 3. 물리 볼륨 4. 볼륨 그룹 5. 논리 볼륨1. 개요물리 디스크를 쓸 수 있게 포맷하고 마운트를 하는 방법을 [RHCSA] Storage 파티셔닝 [RHCSA] Swap 파티셔닝에서 학습하였다.여기서는 LVM 개념을 배운다.LVM은 물리 디스크를 초기화 한 이후에, 그룹핑 개념을 도입하여여러 물리 디스크를 하나의 그룹처럼 묶어줄 수 있게 된다.논리적인 개념으로 만들어주기 때문에 원하는 크기의 가상의 디스크 장치를 만들 수 있다.2. 디스크 초기화 및 파티셔닝# lsblk --fsNAME FSTYPE LABEL UUID MOUNTPOINTvda ├─vda1 ├─vda2 vfat 399C-0F7D /boot/efi└─vda3 xfs root 3cd0d4ca-93f6-423b-a469-70ab2b10b667 /vdb vdc vdd 초기화되지 않은 신규 디스크 장치는 vdb, vdc, vdd# parted -s /dev/vdb mkpart part1 1M 256MB# parted -s /dev/vdb mkpart part2 257M 513MB xfs / ext4 등의 type을 명시하지 않는 것이 특징이다. 두 개(part1, part2)의 파티셔닝을 하였다.# parted /dev/vdb set 1 lvm on# parted /dev/vdb set 2 lvm on lvm type으로 지정한다. 위에서 lvm type을 일괄 지정하는 방법은 보이지 않는다.# parted /dev/vdb printModel: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 256MB 255MB part1 lvm 2 257MB 513MB 256MB part2 lvm 총 2개의 파티션이 LVM으로 잘 준비되었다.# udevadm settle 디스크 장치가 준비되기를 기다리는 것을 잊지 말자…!3. 물리 볼륨phyisical voulume 으로 만들어야 다음 volume group에서 묶을 수 있다. 개별적인 물리 디스크 장치를 논리적으로 묶기 위해 하는 과정# pvcreate /dev/vdb1 /dev/vdb2 각 장치를 volume으로 만들어 컨트롤할 수 있게 된다.# pvs PV VG Fmt Attr PSize PFree /dev/vdb1 lvm2 --- 243.00m 243.00m /dev/vdb2 lvm2 --- 244.00m 244.00m pvs명령으로 간략하게 확인할 수 있다.# pvdisplay &quot;/dev/vdb1&quot; is a new physical volume of &quot;243.00 MiB&quot; --- NEW Physical volume --- PV Name /dev/vdb1 VG Name PV Size 243.00 MiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID qDxeX0-e7my-KvdJ-m8Vs-lvq7-c0lv-wczCWl &quot;/dev/vdb2&quot; is a new physical volume of &quot;244.00 MiB&quot; --- NEW Physical volume --- PV Name /dev/vdb2 VG Name PV Size 244.00 MiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID aEQNQ1-nprf-fuHY-2U2d-puIi-2dlN-3lm5dM pvdisplay 명령으로 모든 volume을 확인할 수 있다. 장치명(PV Name)을 보면 이해가 쉽다.4. 볼륨 그룹앞서 만든 볼륨을 묶어 그룹으로 만들 수 있다.# vgcreate myvg /dev/vdb1 /dev/vdb2# vgs VG #PV #LV #SN Attr VSize VFree myvg 2 0 0 wz--n- 480.00m 480.00m vgs 명령으로 간략히 확인할 수 있다.# vgdisplay --- Volume group --- VG Name myvg System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 2 Act PV 2 VG Size 480.00 MiB PE Size 4.00 MiB Total PE 120 Alloc PE / Size 0 / 0 Free PE / Size 120 / 480.00 MiB VG UUID 2NvDjK-sZyV-BK9C-OlE0-If4P-lLcA-WGn4dZ VG Size: /dev/vdb1과 vdb2의 총합과 같다. PE : LVM 개념으로 만들어진 디스크에서 사용되는 단위. 해당 단위만큼 디스크 용량을 축소/확대 할 수 있다.5. 논리 볼륨생성한 그룹은 하나의 물리 디스크와 같다고 볼 수 있다.해당 디스크를 논리 볼륨이라는 단위로 파티셔닝 하여 쓸 수 있다.# lvcreate -n mylv -L 400MB myvg myvg (/dev/vdb1, vdb2의 합)에서 400MB 만큼만 잘라서 파티셔닝 한다.# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert mylv myvg -wi-a----- 400.00m 간략히 확인할 수 있다.# lvdisplay --- Logical volume --- LV Path /dev/myvg/mylv LV Name mylv VG Name myvg LV UUID Mrx6lv-G0O9-4bhX-r5ef-ISjw-d0aA-qQvDGl LV Write Access read/write LV Creation host, time servera.lab.example.com, 2021-12-08 22:56:00 -0500 LV Status available # open 0 LV Size 400.00 MiB Current LE 100 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:0 눈여겨 볼 것은 LV Path 이다. 마치 실제 디스크 장치와 같다. 그리고, 여기도 PE같이 LE 개념이 있다.# parted /dev/myvg/mylv printError: /dev/dm-0: unrecognised disk labelModel: Linux device-mapper (linear) (dm) Disk /dev/dm-0: 419MBSector size (logical/physical): 512B/512BPartition Table: unknownDisk Flags: (가상의) 디스크 장치가 초기화 되지 않은 로그 내용.# mkfs.xfs /dev/myvg/mylvmeta-data=/dev/myvg/mylv isize=512 agcount=4, agsize=25600 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1data = bsize=4096 blocks=102400, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0, ftype=1log =internal log bsize=4096 blocks=1368, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0 xfs(또는 원하는) 타입으로 초기화.# parted /dev/myvg/mylv printModel: Linux device-mapper (linear) (dm)Disk /dev/dm-0: 419MBSector size (logical/physical): 512B/512BPartition Table: loopDisk Flags:Number Start End Size File system Flags 1 0.00B 419MB 419MB xfs xfs 타입으로 초기화하니, 파티셔닝된 디스크로써 모든 준비가 완료되었다.# mount /path /dev/myvg/mylv 와 같이 마운트할 수 있다." }, { "title": "[Typora] 블로그 이미지 업로드", "url": "/posts/typora_1/", "categories": "GIT Blog, Plugins", "tags": "Typora, PicGo, Jekyll", "date": "2021-12-08 12:41:57 +0900", "snippet": "Contents 1. 개요 2. Typora 2.1 이미지의 시작지점 (root) 지정 2.2 Typora Image 메뉴 설정 2.3 포스팅 후 게시글 확인 1. 개요blog post 작성 시 이미지 업로드를 위해 Typora 에 PicGo 를 활용했었는데,이미지가 한 곳에 모두 쌓이다 보니 어느 post에서 생성된 이미지인지 분간이 어렵다.포스트별 디렉토리를 생성하고, 그 안에 이미지를 업로드 하도록 설정한다.2. Typora2.1 이미지의 시작지점 (root) 지정Format &amp;gt; Image &amp;gt; Use Image Root Path 메뉴디렉토리는 다음 이미지처럼 최상단을 지정한다.이렇게 설정하거나, 다음과 같이 YAML Front Matter typora-root-url 를 집어넣는다.---title: &quot;[Typora] 블로그 이미지 업로드&quot;date: 2021-12-08 12:41:57 +0900categories: [GIT Blog, Plugins]tags: [Typora, PicGo, Jekyll]author: DongHyun Kimtypora-root-url: ..--- .md 파일이 _posts 에 있으니, image를 상단(..) 에서 상대경로로 읽으라고 지정하는 것이다.2.2 Typora Image 메뉴 설정환경 설정에서 Image를 다음과 같이 설정한다.클립보드 이미지 또는 드래그&amp;amp;드랍으로 삽입하는 이미지를 assets/img/&amp;lt;md 파일명 디렉토리/ 안에 넣는다.실제로 이미지는 md 파일명을 디렉토리로 삼고, 그 안에 들어간다. 2021 날짜가 붙은것은, 블로그를 포스팅 완료 후 이미지를 삽입한 게시물들이 있어 저렇게 나올 뿐이다. 현재 이 게시믈 typora_1.md 는 아직 포스팅 하지 않은 상태로 작성 중이다.2.3 포스팅 후 게시글 확인포스팅 후 확인해보면 이미지가 잘 나타나고, 이미지 별로 다음과 같이 URL이 생성된다.http://dhkim900331.github.io/assets/img/typora_1/image-20211208124053829.png" }, { "title": "[RHCSA] Swap 파티셔닝", "url": "/posts/rhcsa_partioning_2/", "categories": "Study, RHCSA", "tags": "Study, RHCSA, Swap, GPT, MBR, parted", "date": "2021-12-07 21:05:50 +0900", "snippet": "Contents 1. 개요 2. Swap 2.1 파티션 생성 2.2 Swap 활성화 1. 개요RHCSA 과정을 준비하면서, Swap파티셔닝을 정리한다.fdisk, gdisk 를 먼저 공부했지만, parted 가 너무 편리하여 parted로 정리한다.Swap이 아닌 일반 스토리지는 여기를 클릭2. Swap일반 스토리지 단계에서부터 이어서 진행한다.# parted /dev/vdb printModel: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 17.4kB 2000MB 2000MB xfs backup 현재 장치 정보는 위와 같은 상태2.1 파티션 생성# parted /dev/vdb mkpart swap1 linux-swap 2001MB 2513MBInformation: You may need to update /etc/fstab.# parted /dev/vdb mkpart swap2 linux-swap 2514MB 3026MBInformation: You may need to update /etc/fstab. swap1, swap2 이름의 linux-swap 속성, 각각 512MB 크기를 2개 만들었다.# parted /dev/vdb print Model: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 17.4kB 2000MB 2000MB xfs backup 2 2001MB 2513MB 513MB swap1 swap 3 2514MB 3026MB 512MB swap2 swap print로 확인# udevadm settle 여기서는 헷갈리지 않고 해당 명령어를 잘 사용했다 ^^# mkswap /dev/vdb2Setting up swapspace version 1, size = 489 MiB (512749568 bytes)no label, UUID=52c19f22-9abe-4e8a-94ac-bb6689e18e4b# mkswap /dev/vdb3Setting up swapspace version 1, size = 488 MiB (511700992 bytes)no label, UUID=00eb7f1a-1082-49cb-bd04-8b1d8a48e7a4 파일 시스템을 swap으로 잘 지정하였다. 여기도 UUID를 잘 어딘가에 기록해둔다.# parted /dev/vdb printModel: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 17.4kB 2000MB 2000MB xfs backup 2 2001MB 2513MB 513MB linux-swap(v1) swap1 swap 3 2514MB 3026MB 512MB linux-swap(v1) swap2 swap print로 swap 까지 잘 확인되는 모습2.2 Swap 활성화UUID=52c19f22-9abe-4e8a-94ac-bb6689e18e4b swap swap defaults 0 0UUID=00eb7f1a-1082-49cb-bd04-8b1d8a48e7a4 swap swap pri=10 0 0 /etc/fstab 으로 영구적으로 활성화 할 수 있게 설정한다. pri=10은 가장 먼저 사용하는 우선순위 개념.# swapon --show# swapon /dev/vdb2# swapon /dev/vdb3# swapon --showNAME TYPE SIZE USED PRIO/dev/vdb2 partition 489M 0B -2/dev/vdb3 partition 488M 0B -3 1: show 명령으로 활성화된 swap이 있는지 살펴보지만 없다. _2-3: 각각 장치를 활성화하였다. 4-7: 정상적으로 활성화되었다고 확인된다. /dev/vdb3 의 PRIO는 -3을 나온다. reboot 해야 적용된다.# systemctl reboot...# swapon --showNAME TYPE SIZE USED PRIO/dev/vdb3 partition 488M 0B 10/dev/vdb2 partition 489M 0B -2# free -htotal used free shared buff/cache availableMem: 1.8Gi 177Mi 1.4Gi 16Mi 188Mi 1.5GiSwap: 976Mi 0B 976Mi 시스템 reboot 이후 swap 활성화가 잘 되어 있으며, 메모리에도 잘잡힌다." }, { "title": "[RHCSA] Storage 파티셔닝", "url": "/posts/rhcsa_partioning_1/", "categories": "Study, RHCSA", "tags": "Study, RHCSA, Storage, GPT, MBR, parted", "date": "2021-12-07 21:05:50 +0900", "snippet": "Contents 1. 개요 2. MBR / GPT 3. GPT 파티셔닝 3.1 사용 가능한 디스크 확인 3.2 디스크 라벨링 3.3 파티션 생성 3.4 파일시스템 마운트 1. 개요RHCSA 과정을 준비하면서, Storage 파티셔닝을 정리한다.fdisk, gdisk 를 먼저 공부했지만, parted 가 너무 편리하여 parted로 정리한다.2. MBR / GPTMBR과 GPT의 차이점 등은 다른 구글링으로 쉽게 찾아볼 수 있다.아래 Section 실습에서는 MBR 이든 GPT이든 mklabel 에서만 지정하면 된다. 예시 parted /dev/vdb mklabel msdos # MBRparted /dev/vdb mklabel gpt # GPT 너무 편리하다..3. GPT 파티셔닝 MBR 파티셔닝은 msdos 로 label 만 주면 되므로, GPT 로 설명한다.3.1 사용 가능한 디스크 확인# lsblk --fsNAME FSTYPE LABEL UUID MOUNTPOINTvda ├─vda1 ├─vda2 vfat 399C-0F7D /boot/efi└─vda3 xfs root 3cd0d4ca-93f6-423b-a469-70ab2b10b667 /vdb vdc vdd 새로운 디스크(HDD or SDD 등)를 붙이면 /dev/vd{a~…z} 으로 추가 된다.# parted /dev/vdb printError: /dev/vdb: unrecognised disk labelModel: Virtio Block Device (virtblk) Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: unknownDisk Flags: /dev/vdb 를 확인해보니 disk label 이 없다는 error와, Partion table이 unknown 이라는 것이 확인된다.3.2 디스크 라벨링# parted /dev/vdb mklabel gptInformation: You may need to update /etc/fstab. /dev/vdb 디스크를 GPT 라벨링 MBR일 경우 gpt -&amp;gt; msdos# parted /dev/vdb print Model: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags print 명령으로 GPT 라벨링 여부도 확인된다.3.3 파티션 생성# parted /dev/vdb mkpart backup xfs 1s 2GBWarning: You requested a partition from 512B to 2000MB (sectors 1..3906250).The closest location we can manage is 17.4kB to 2000MB (sectors 34..3906250).Is this still acceptable to you?Yes/No? Yes Warning: The resulting partition is not properly aligned for best performance:34s % 2048s != 0sIgnore/Cancel? Ignore Information: You may need to update /etc/fstab. /dev/vdb 에 최초 파티션을 생성하엿다. 파티션 명: backup 파티션 타입: xfs 파티션 크기: 2GB ​ ㄴ최초 파티션이므로, 가장 최소단위 1Sector 부터 2GB 까지 설정) ​ _ㄴ”3.2” 에서 Sector size 를 알 수 있다.__ _MBR일 경우 backup -&amp;gt; primary(경우에 따라 extended)# parted /dev/vdb print Model: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 17.4kB 2000MB 2000MB backup print의 결과를 보면, 원하는 대로 생성되어 있다. 1s = 512B 라 예상되지만, 시스템은 최소 크기가 17.4kB 인듯 하다# mkfs.xfs /dev/vdb1meta-data=/dev/vdb1 isize=512 agcount=4, agsize=122070 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1data = bsize=4096 blocks=488277, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0, ftype=1log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0# parted /dev/vdb printModel: Virtio Block Device (virtblk)Disk /dev/vdb: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 17.4kB 2000MB 2000MB xfs backup 파티션의 파일 시스템 유형을 xfs로 선언하고 print로 확인한 모습# udevadm settle /dev/vda1 장치가 준비되는 것을 기다려주는 명령어원래 윗부분(mkfs)보다 일찍 사용해야 하는데.. 자꾸 이렇게 외워버렸다.3.4 파일시스템 마운트실제 디렉토리로 마운트 지점을 할당해야 쓸 수 있다.# mkdir /backup 마운트 지점 디렉토리를 생성한다.# lsblk --fsNAME FSTYPE LABEL UUID MOUNTPOINTvda ├─vda1 ├─vda2 vfat 399C-0F7D /boot/efi└─vda3 xfs root 3cd0d4ca-93f6-423b-a469-70ab2b10b667 /vdb └─vdb1 xfs 3b1e73fa-409b-459c-aeaf-8866cef00f32vdc vdd /dev/vdb1 파티션의 UUID를 확인한다.UUID=3b1e73fa-409b-459c-aeaf-8866cef00f32 /backup xfs defaults 0 0 /etc/fstab 파일에 위 내용을 추가한다.# systemctl daemon-reload /etc/fstab 파일을 시스템이 다시 읽도록 한다.# mount /backup# mount | grep vdb1/dev/vdb1 on /backup type xfs (rw,relatime,seclabel,attr2,inode64,noquota) 실제 mount 가 되도록 하고, 잘 되었는지 확인하는 모습이제 systemctl reboot 으로 재부팅하여도 mount가 항상 되어있다." }, { "title": "[WebLogic] Administration Port, Side-By-Side Deploy", "url": "/posts/weblogic_tip_4/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, Deploy", "date": "2021-12-07 18:16:49 +0900", "snippet": "Contents 1. 개요 2. Administration Port 2.1 설정 방법 2.1.1 Admin Server 2.1.2 Managed Server 2.1.3 Start Server 2.1.4 Stop Server 3. Side-By-Side Deploy 3.1 배포된 어플리케이션의 상태와 커맨드 3.1.1 Active State 3.1.2 Stop Running State 3.1.3 ADMIN State 1. 개요Administration Port, Side-By-Side Deploy 기능을 알아보자.2. Administration Port SSL 을 사용하여 웹로직 콘솔에 접근 하도록 한다. 알려지지 않은 포트로 포워딩 시킴으로써, 보안에 유리하다.(원래 7001포트 -&amp;gt; 7200포트 등.. 사용자 정의에 의함) 매니지드 서버도 Administration Port를 해서 관리해야되는 단점이 있다.2.1 설정 방법2.1.1 Admin Server(1). Managed Shutdown(2). console - domain - configuration - general - Enable Administration Port, Administration Port(3). https://ip : administration Port로 console을 재접속한다.2.1.2 Managed ServerConfiguration - General - Advanced - Local Administration Port Override : Administration Port가 Managed Server 마다 Unique해야 된다.2.1.3 Start Server(1). admin url = t3s://adminIP : administration port(2). JAVA_OPTIONS=”-Dweblogic.security.TrustKeyStore=DemoTrust”2.1.4 Stop Server(1). exit url = t3s://managed ip : managed administration port(2). JAVA_OPTIONS=”-Dweblogic.security.TrustKeyStore=DemoTrust” * DemoTrust 말고도… 다양하게 설정할 방법이 있을텐데…3. Side-By-Side Deploy어플리케이션을 서비스 중지없이 업데이트하여 버전 관리가 가능하다.3.1 배포된 어플리케이션의 상태와 커맨드3.1.1 Active State모든 사용자가 접근 가능한 어플리케이션 상태.타겟 인스턴스가 기동 중이지 않으면 New state기동 중이면 Activice statejava -Dweblogic.security.TrustKeyStore=DemoTrust weblogic.Deployer -adminurl t3://adminServer_Address -user weblogic -password weblogic1 -deploy -name webapp -source D:\\weblogic\\WLS1036\\domains\\dm1036\\webapp -targets m1 -appversion v1 appversion 파라메터가 버전 관리를 위해 잘 관리해줘야 한다.3.1.2 Stop Running State구 버전 어플리케이션과 신 버전 어플리케이션의 관리java -Dweblogic.security.TrustKeyStore=DemoTrust weblogic.Deployer -adminurl t3://adminServer_Address -user weblogic -password weblogic1 -deploy -name webapp -source D:\\weblogic\\WLS1036\\domains\\dm1036\\webapp -targets m1 -appversion v2 webapp(v1)은 아직 사용자가 있어서 stop Running… 다 빠져나가면 retired가 된다. webapp(v2)로 이후 신규 사용자가 접속된다.3.1.3 ADMIN Stateadministration port를 사용 중인 admin server 환경에서 어플리케이션의 오픈전 테스트를 위해 사용한다.ADMIN state 어플리케이션은 웹로직 ‘myrealm’에 허가된 유저&amp;amp;그룹만 접근가능한데,administration port를 사용하여 접근하는 행위가 허가된 유저&amp;amp;그룹 인증 절차이기 때문이다.java -Dweblogic.security.TrustKeyStore=DemoTrust weblogic.Deployer -adminurl t3s://adminServerIP:administrationPORT -user weblogic -password weblogic1 -adminmode -name webapp -deploy -upload -remote D:\\weblogic\\WLS1036\\domains\\dm1036\\webapp 위 커맨드 실행 결과가 remove Initializing 일 수 있다… admin server restart 하니 admin state이다…" }, { "title": "[WebLogic] JMX MBean 사용을 위한 기초 개념", "url": "/posts/weblogic_tip_3/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, MBean, JMX", "date": "2021-12-07 18:16:49 +0900", "snippet": "Contents 1. 개요 2. WebLogic 에서 MBean 이란? 3. WebLogic 에서 MBean 접근 방법 3.1 사용할 MBean 3.2 MBean 접근 1. 개요WebLogic 환경에서 MBean 사용방법을 간단하게 알아보자2. WebLogic 에서 MBean 이란? 웹로직의 모든 접근 가능한 정보들은 MBeanServer에 저장된다. 웹로직 콘솔 페이지 또한 이 MBeanServer를 보여주는 것에 불과하다. MBeanServer는 계층적 구조를 가지고 있으며, 접근하기 위해서는 JMX API를 구현한 MBeans로 가능하다. 이 MBean에 접근하여 수정하는 코드를 만든다면, 웹로직 콘솔을 커스터마이즈 하는 것과 동일하다.3. WebLogic 에서 MBean 접근 방법3.1 사용할 MBean먼저 MBeans 구조에 접근하기 위해서는 어떤 Service를 제공하는 MBean에 접근할지를 정해야 한다. DomainRuntimeServiceMBean : 전체 도메인에 대하여 어플리케이션 배치, JMS 서버, JDBC 데이터소스 등을 제공한다. RuntimeServiceMBean : 현재 서버에 대한 정보를 제공한다. EditServiceBean : 현재 웹로직 도메인의 설정을 관리한다.위 서비스 중 하나를 접근하기 위해선 각기 다른 JMX Object Name을 알아야 한다. DomainRuntimeServiceMBean : com.bea:Name=DomainRuntimeService,Type=weblogic.management.mbeanservers.domainruntime.DomainRuntimeServiceMBean RuntimeServiceMBean : com.bea:Name=RuntimeService,Type=weblogic.management.mbeanservers.runtime.RuntimeServiceMBean EditServiceBean : com.bea:Name=EditService, Type=weblogic.management. mbeanservers.edit. EditServiceMBean 출처 : http://docs.oracle.com/cd/E24329_01/web.1211/e24415/understandwls.htm#JMXCU1303.2 MBean 접근자, 이제 위에 설명한 3개의 서비스 중 원하는 하나를 골랐다면, 해당 되는 MBean 서버에 접근 할 수단이 필요하다. 왜 수단이 필요하냐고 묻는다면, 1번에서 설명하였듯이 MBean 제어는 JMX API를 통해 이루어지기 때문이다.접근은 javax.management.remote.JMXServiceURL 객체를 통해 한다. 접근이라는 의미는 실제로 웹로직 아이피와 포트, Admin id/pwd 정보를 기재하고 다음 프로토콜을 사용하여 MBean 서버에 전달하는 것을 의미한다. t3, t3s, http, https, iiop, iiops 중 하나를 사용한다. MBeans는 결국 인스턴스의 JNDI 정보를 보는 것과 동일하다. MBeans 서버에 접근하려면 JMXServiceURL의 첫 시작은 /jndi/ 이어야만 한다.접근할 수단이라는 것에 대해 알았다. 그렇다면 실제 URL은? DomainRuntimeMBeanServer : weblogic.management.mbeanservers.domainruntime RuntimeMBeanServer : weblogic.management.mbeanservers.runtime EditMBeanServer : weblogic.management.mbeanservers.edit3가지 중 하나의 ServiceBean을 정했고,ServiceBean의 JMX Object Name을 알아냈다.접근하는 방법도 알았다.예시는 다음과 같다. 현재 서버에 대한 정보 중 배포 되어 있는 어플리케이션 들이 무엇무엇이 있고, Targets 값은 무엇으로 되어있는지가 궁금하다RuntimeServiceMBean , com.bea:Name=RuntimeService,Type=weblogic.management.mbeanservers.runtime.RuntimeServiceMBean , /jndi/weblogic.management.mbeanservers.runtime" }, { "title": "[WebLogic] WLST으로 Thread Dump", "url": "/posts/weblogic_tip_2/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, WLST, ThreadDump", "date": "2021-12-07 15:34:11 +0900", "snippet": "Contents 1. 개요 2. 설명1. 개요WLST로 Thread dump를 뜨는 스크립트2. 설명java -cp wlfullclient.jar weblogic.Admin -url t3://ip:port -username weblogic -password weblogic1 THREAD_DUMP nohup에 기록된다. wlfullclient.jar는 https://docs.oracle.com/cd/E13222_01/wls/docs103/client/jarbuilder.html#wp1078098 를 참고하여 생성한다." }, { "title": "[WebLogic] weblogic.socket.muxer is blocked", "url": "/posts/weblogic_tip_1/", "categories": "WAS, WebLogic", "tags": "WAS, WebLogic, muxer", "date": "2021-12-07 12:41:58 +0900", "snippet": "Contents 1. 개요 2. 설명1. 개요스레드 덤프에서 muxer Thread가 blocked 으로 보여지는 현상은 무엇일까?2. 설명웹로직 스레드 덤프를 떠보면, muxer 중 1개는 waiting on condition , 1개는 blocked 상태에 머무는 것이 확인된다.스레드 경합을 피하기 위해, blocked, waiting on condition 의 상태를 수시로 갖게 된다.muxer 자체가 매우 빠르게 동작하기 위함이며, 실제로도 많은 작업을 하지 않기 때문에 덤프를 뜰때마다 그렇게 보이는 것으로 이해된다. Java Socket Muxer - polling 방식 Native Socket (Native Muxer; 웹로직 기본 muxer) - interrupt 방식 Is It Normal to See Blocked “weblogic.socket.muxer” Threads? (Doc ID 857031.1)" }, { "title": "[WebLogic] 금융권 MultiDataSource 이슈 사례", "url": "/posts/weblogic_issue_3/", "categories": "WAS, WebLogic", "tags": "WebLogic, Issues, MultiDataSource", "date": "2021-12-06 00:00:00 +0900", "snippet": "Contents 1. 개요 2. 현상 3. 해결 3.1 해결을 위해 참고한 문서들 (1). MultiDatasource에서 장애를 인지하고, Failover 시키는 메커니즘. (2). MultiDataSource 의 Failover 동작 메커니즘 1. 개요Multidatasource 사용 중인 고객사에서 발생한 장애2. 현상데이터소스 이름과 설정 내용ADataSource_1 (MultiDataSource; Failover, DB#1, DB#2)ADataSource_2 (MultiDataSource; Failover, DB#2, DB#1)(1). 고객사 물리 DB는 2대이며, DB#2번 스토리지 장애 발생.(2). DB#2번 장애로 인해, WebLogic ADataSource_1 Multi DataSource force disabled 및모든 세션이 DB#1번으로 연결되는 ADataSource_2 으로 쏠림.(3). ORA-12520 에러 발생ADataSource_1 번에 모든 세션이 몰리면서 DB#1번 Max Process 도달하였음.ADatSource_1 disabled.(4). 시간이 지나 DB#2번 정상화 되어,ADataSource_2 re-enabled.(5). 그러나 ADataSource_1 번은 re-enabled 되지 않고, 다음날 오전까지 disabled 상태.(6). 더 이상 재현되지 않고, 의심가는 부분이 발견되지 않아 가진 로그만으로 해결 불가능.3. 해결3.1 해결을 위해 참고한 문서들(1). MultiDatasource에서 장애를 인지하고, Failover 시키는 메커니즘. “BEA-000639”,”BEA-001584”,”BEA-001117” Printed in Server Log Repeatedly ( Doc ID 2474159.1 ) 문서에서는 Multi Data Source Fail-Over Limitations and Requirements 를 참고하면 됨.Test Connections on Reserve to Enable Fail-Over : 테스트 커넥션 기능으로 감지.No Fail-Over for In-Use Connections : Connection은 AP와 직접 할당되므로, 중간에 이를 생성/할당해준 DataSource는 문제의 Connection을 강제로 회수할 수가 없음. (정확히는 사용중인 커넥션)AP(Logic)에서 문제의 Connection을 close(con.close();) 하고 새로운 연결을 시도해야 한다는 의미.여기서 No Fail-Over for In-Use Connections 부분을 좀 유심히 봐야될 필요가 있었는데,고객사는 MultiDatasource 구성이었다.여기서 더 나은 환경을 위해 Generic DataSource + TAF 구성을 가져가면, No Fail-Over for In-Use Connections 이슈를 회피할 수 있는지에 관심을 가졌다.그러나, TAF 구성으로 가더라도, Connection 자체는 AP와 DB가 직접적으로 관계를 맺고 있기 때문에여전히 No Fail-Over for In-Use Connections 문제는 발생할 수 있다.다만 TAF 기능을 통해 DB-tier에서의 Failover(rac) 를 기대해볼 수만 있다.(2). MultiDataSource 의 Failover 동작 메커니즘 https://docs.oracle.com/middleware/1213/wls/JDBCA/jdbc_multidatasources.htm#JDBCA220Connection Request Routing Enhancements When a Generic Data Source Fails : 일반 데이터소스 실패 시, Disabled 하여 서비스 라우팅 성능 향상이라는 원론적인 설명 Automatic Re-enablement on Recovery of a Failed Generic Data Source within a Multi Data Source : Disabled 일반 데이터소스 주기적으로 테스트하여 재복구한다는 것 Enabling Failover for Busy Generic Data Sources in a Multi Data Source : Failover 기능 사용시, Max Capacity 초과해서 오는 Request는 다음 DataSource에 전달 한다는 기능 Controlling Multi Data Source Failover with a Callback : CallBack Handler 설명 (AP 로직에서 쓸경우..)" }, { "title": "[WebLogic] WLDF", "url": "/posts/weblogic_issue_2/", "categories": "WAS, WebLogic", "tags": "WebLogic, Issues, WLDF", "date": "2021-12-06 00:00:00 +0900", "snippet": "Contents 1. 개요 2. 현상 2.1 WLDF 2.2 WLDF 파일로 인해 문제 발생 3. 해결 3.1 첫번째 방법 3.2 두번째 방법 (권장?) 1. 개요SR 3-18108256751 : [건강보험공단] every hour cpu spike 건을 정리2. 현상2.1 WLDFWebLogic Diagnostics Frameworkservers//data/store/diagnostics/WLS_DIAGNOSTICS000000.DAT 파일로 저장.12cR1 기준으로, 5분마다 위 데이터 수집.1시간마다 용량 100mb 도달 시, old record 삭제.2.2 WLDF 파일로 인해 문제 발생건보에서 1시간마다 cpu spike 발생.진단파일 손상 되었을 것으로 예상한다는 오라클 답변이지만,에러 로그가 없는 것에 대해서는디버그 하면 볼 수 있을 것이라는 답변3. 해결3.1 첫번째 방법1차 파일 삭제, 재기동으로 클리어 후에도 용량이 90mb 도달시에1시간마다 cpu spike 동일 증상 발생하는 것으로 보아용량과 관계 있어 보여.우선 기능 disable 옵션 아래 적용. How to Prevent the ‘WLS_DIAGNOSTICSxxxxxx.DAT’ file (under the DOMAIN_NAME/servers/SERVER_NAME/data/store/diagnostics folder) From Growing Too Large (문서 ID 965416.1)-Dcom.bea.wlw.netui.disableInstrumentation=true-D_Offline_FileDataArchive=true-Dweblogic.connector.ConnectionPoolProfilingEnabled=false-Dcom.bea… Dcom.bea… : page flow event 로깅을 하지 않음 이라고 답변받았다. (https://docs.oracle.com/cd/E13218_01/wlp/docs81/ipcguide/custevent.html&amp;gt; 의 What is a Page Flow Event?) 에 정확한 설명은 있으나, 이해 안감.. 로그인 웹페이지를 보여주는 포틀릿과, 다른 포틀릿간의 상호 연계(호출 또는 아이디/패스워드를 수집하여 db로 보낸다는건지..)를 기록할 수 있고, 이러한 기록기능을 disable 하는 것으로 보임.-D_Offline… 진단파일을 언제나 빠르게 검색하게 하기 위한 색인화(indexer)를 중지. 라고 답변받았으나, (How Can I Reduce the Size of the Logs Produced by the WebLogic Diagnostic Framework (WLDF)? (문서 ID 950742.1)) 문서에서는 위 Dcom.bea.. 옵션도 같이 사용해야 하는 것으로 설명되어 있다.-Dweblogic.connector… JDBC 데이터소스 설정에 커넥션 프로파일링(커넥션 Leak 을 잡기 위해 주로 사용) 로그를 진단파일에 기록하지 않는다고 되어있다. 몇건의 사례에서, 위 프로파일링으로 인해 진단파일을 오랫동안 기록, 많은 양을 기록하여 문제된 적이 발견된다.위와 같이 정리를 하고보면, 세개의 옵션은 몇가지 기능을 끄는 것으로 disable 효과를 볼 수는 있으나WLDF 진단파일 공식문서에서는 MBeans, 시스템 상태 등등 더 부피가 큰 데이터를 기록하는게 기본이다…즉 위 옵션은 용량이 큰 진단파일을 더 작게 리사이징 하는 정도의 옵션이다.Doc ID. 950742.1 문서에도 reduce size 로 표현되고 있다.3.2 두번째 방법 (권장?)콘솔 - Diagnostics - Built-in Diagnostic Modules - - Low 값을 None 으로 변경. 3.1 옵션을 적용하지 않아도 되며, 파일에 아무런 기록을 하지 않는다. 기본 파일은 생성이 된다." }, { "title": "[WebLogic] XAConnection java.sql.SQLException: XA error: XAResource.XAER_RMFAIL start() failed", "url": "/posts/weblogic_issue_1/", "categories": "WAS, WebLogic", "tags": "WebLogic, Issues, XAConnection, SQLException", "date": "2021-12-06 00:00:00 +0900", "snippet": "Contents 1. 개요 2. 현상 3. 해결1. 개요2019년 02월 고객사 일부 장애 건 정리.2. 현상웹로직 서버로그에는 나오지 않으나…어플리케이션 노헙 로그에서는 아래와 같은게 발견된 적이 있다.XAConnection java.sql.SQLException: XA error: XAResource.XAER_RMFAIL start() failed on resource3. 해결오라클 문서에서 가이드 하는 내용은. DB 쪽에 maximum process 확인. DB init.ora의 DISTRIBUTED_LOCKOUT 값 확인.이중 LOCKOUT은 기본값 60초이며,DB를 insert,delete,update 등으로 사용자가 점유하고 있으면, table lock을 걸어두고 사용해야 한다.이 lock을 기다리는 최대 시간을 의미하는 것으로 보여진다.웹로직 에서 DB까지의 흐름을 보면 graph LR; WebLogic --&amp;gt; JTA[JTA Timeout]; JTA --&amp;gt; XA[XA Timeout]; XA --&amp;gt; DB[DB Lockout Timeout]; JTA timeout : 웹로직에서 트랜잭션 전체 크기에 해당하는 time만큼 지정해야 한다. 클라이언트가 결과를 받을 때까지를 의미하기 때문에, DB단까지 포함해야 한다. XA timeout : XA 로직 실행 타임아웃. LOCKOUT : DB Table lock 대기 시간.나도 헷갈려서 정리를 나중에 다시 해야겠는데..어쨋든.. LOCKOUT이 실제 업무 타임보다 짧아, 기본값 60초만 기다리고 업무를 보지 못하고 rollback 되는 경우가 있다는 것 같다;;" }, { "title": "[Ansible/2.9] 기본 playbook 테스트", "url": "/posts/ansible_2/", "categories": "Ansible", "tags": "Ansible, Install, playbook", "date": "2021-12-06 00:00:00 +0900", "snippet": "Contents 1. 개요 2. 테스트1. 개요Ansible installation 후에 Sample Playbook testing.2. 테스트hosts 파일에 테스트용 VM 을 나열하고,/tmp 에 디렉토리 생성 playbook/tmp 에 생성한 디렉토리 삭제 playbook위 playbook 을 all-in-one 으로 만드는 import playbook총 3가지 테스트한 파일20210803.tar.gz" }, { "title": "[Ansible/2.9] Installation", "url": "/posts/ansible_1/", "categories": "Ansible", "tags": "Ansible, Install", "date": "2021-12-06 00:00:00 +0900", "snippet": "Contents 1. 개요 2. 설치1. 개요Ansible installation2. 설치CentOS Version$ cat /etc/*releaseCentOS Stream release 8NAME=&quot;CentOS Stream&quot;VERSION=&quot;8&quot;ID=&quot;centos&quot;ID_LIKE=&quot;rhel fedora&quot;VERSION_ID=&quot;8&quot;PLATFORM_ID=&quot;platform:el8&quot;PRETTY_NAME=&quot;CentOS Stream 8&quot;ANSI_COLOR=&quot;0;31&quot;CPE_NAME=&quot;cpe:/o:centos:centos:8&quot;HOME_URL=&quot;https://centos.org/&quot;BUG_REPORT_URL=&quot;https://bugzilla.redhat.com/&quot;REDHAT_SUPPORT_PRODUCT=&quot;Red Hat Enterprise Linux 8&quot;REDHAT_SUPPORT_PRODUCT_VERSION=&quot;CentOS Stream&quot;CentOS Stream release 8CentOS Stream release 8참고하여 CentOS 8에 설치 하였다. https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installing-ansible-on-rhel-centos-or-fedoraOralce Linux 7 VM은 다음 링크 https://blogs.oracle.com/scoter/ansible-with-oracle-linux-virtualization-manager-olvm각각 VM에 다음 링크 대로 적용하여 nopass 설정하였다.ansible 이 각 VM 에 명령어 실행 시, password 인자를 줄 수 있지만,이번 설치 및 테스트 환경에서는 nopass 설정을 하였다. https://devfon.tistory.com/31/etc/ansible 에 설치완료" }, { "title": "[Mermaid] Mermaid 기능 사용", "url": "/posts/mermaid_1/", "categories": "GIT Blog, Plugins", "tags": "Mermaid, Jekyll, Graph, Chart", "date": "2021-12-06 00:00:00 +0900", "snippet": "Contents 1. 개요 2. mermaid 설치 2.1 javascript 삽입 2.2 mermaid api 호출 1. 개요Jekyll github blog에서 mermaid 를 사용하여 graph(chart 등)이 그려지지 않았었다.git white plug list라는 word 로 검색을 해보니, 현재 mermaid plugin은 지원하지 않고 있어javascript 삽입 방식으로 사용해야 한다.2. mermaid 설치여기를 눌러 보면 Mermaid plugins 사용 방법을 확인할 수 있다.아래의 내용과 동일하다.2.1 javascript 삽입_include/head.html 파일 끝에 삽입한다.&amp;lt;script src=&quot;https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js&quot;&amp;gt; mermaid.initialize({ startOnLoad: true });&amp;lt;/script&amp;gt;2.2 mermaid api 호출&amp;lt;div class=&quot;mermaid&quot;&amp;gt; graph LR; WebLogic --&amp;gt; JTA[JTA Timeout]; JTA --&amp;gt; XA[XA Timeout]; XA --&amp;gt; DB[DB Lockout Timeout];&amp;lt;/div&amp;gt;위 상자안의 일반 텍스트만 사용하면 다음과 같이 그릴 수 있다. graph LR; WebLogic --&amp;gt; JTA[JTA Timeout]; JTA --&amp;gt; XA[XA Timeout]; XA --&amp;gt; DB[DB Lockout Timeout]; mermaid.initialize 메서드가 div class 를 해독하여 렌더링 한다." }, { "title": "[WebLogic] UDDI Explorer 보안 취약점", "url": "/posts/weblogic_issue_4/", "categories": "WAS, WebLogic", "tags": "WebLogic, Issues, UDDI, Explorer", "date": "2021-12-04 00:00:00 +0900", "snippet": "Contents 1. 개요 2. UDDI Explorer ? 3. UDDI Explorer 제거 방법 4. 정상 적으로 제거 하였는지 확인 방법1. 개요WebLogic UDDI Explorer 보안 취약점 제거 방법을 소개한다.2. UDDI Explorer ?UDDI Explorer는 WebService 를 구현하실 때 편의를 위해 제공하는 라이브러리.3. UDDI Explorer 제거 방법UDDI Explorer는 WebService 를 구현하실 때 편의를 위해 제공하는 라이브러리로따로 API를 가지고 구현해서 사용하지 않으시면 해당 라이브러리를 삭제하셔도 됩니다.오라클에서도 보안쪽 advisories 로 공지한 부분으로,10.3 이전버전에서는 패치가 제공되며 이후 버전은 실제 파일을 삭제해야합니다.삭제하시는 방법은 다음과 같습니다.1. Shut down running WLS servers.2. Remove uddi.properties, uddi.war &amp;amp; uddiexplorer.war files under the &amp;lt;WL_HOME&amp;gt;/server/lib/ folder. *Steps 3 and 4 only required if the server server had be started before and tmp directory had been created3. Clear &amp;lt;DOMAIN_HOME&amp;gt;/servers/&amp;lt;SERVER_NAME&amp;gt;/tmp/.internal/ folder.4. Remove the two folders under &amp;lt;DOMAIN_HOME&amp;gt;/servers/&amp;lt;SERVER_NAME&amp;gt;/tmp/_WL_internal/uddi*;5. Restart the WLS admin server You should see warning messages like these in your startup log (and/or sysout):.4. 정상 적으로 제거 하였는지 확인 방법로그상에 다음과 같은 메시지가 떠야 정상적으로 disable 설정됨.&amp;lt;Nov 07, 2011 3:02:31 PM EST&amp;gt; &amp;lt;Warning&amp;gt; &amp;lt;Deployer&amp;gt; &amp;lt;BEA-149617&amp;gt; &amp;lt;Non-critical internal application uddi was not deployed. Error: [Deployer:149158]No application files exist at &#39;C:\\Oracle\\Middleware\\wls103\\WEBLOG~1\\server\\lib\\uddi.war&#39;.&amp;gt;&amp;lt;Nov 07, 2011 3:02:31 PM EST&amp;gt; &amp;lt;Warning&amp;gt; &amp;lt;Deployer&amp;gt; &amp;lt;BEA-149617&amp;gt; &amp;lt;Non-critical internal application uddiexplorer was not deployed. Error: [Deployer:149158]No application files exist at &#39;C:\\Oracle\\Middleware\\wls103\\WEBLOG~1\\server\\lib\\uddiexplorer.war&#39;.&amp;gt;" }, { "title": "[Jenkins] 설치", "url": "/posts/jenkins_1/", "categories": "Jenkins", "tags": "Jenkins, CICD, first-posting", "date": "2021-11-26 17:00:00 +0900", "snippet": "Table of Contents 1. 개요 2. 설치 2.1 다운로드 2.2 Tomcat 환경변수 설정 2.3 war를 배포 3. Tomcat (jenkins) 시작 3.1 기동 시 로그에 아래처럼 초기 패스워드가 확인된다. 3.2 플러그인 설치 3.3 로그인 1. 개요Tomcat 에 Jenkins 설치Jenkins 는 기본적으로 jetty 로 구성되어 패키지 제공되고 있으나,war를 Tomcat에 배포하는 것으로 설치해보기로 한다.2. 설치2.1 다운로드여기 클릭위 LTS 항목을 다운로드 받았다.2.2 Tomcat 환경변수 설정JEKINS_HOME만 세팅하였다.export JENKINS_HOME=&quot;your path&quot;2.3 war를 배포/app/servers/tomcat1/webapps/jenkins.war여기까지가 아주 심플하게 설치는 완료되었다.3. Tomcat (jenkins) 시작3.1 기동 시 로그에 아래처럼 초기 패스워드가 확인된다.**************************************************************************************************************************Jenkins initial setup is required. An admin user has been created and a password generated.Please use the following password to proceed to installation:1c0cba1ae6ef4b8a812978b4f578443eThis may also be found at: /app/servers/tomcat1/jekins_home/secrets/initialAdminPassword***************************************************************************************************************************************************************************************http://tomcat-addr/jekins 에서 위 패스워드로 접속을 한다.3.2 플러그인 설치여기 시스템은 폐쇄망이 아니므로 제안하는 권장 플러그인 리스트를 설치한다.플러그인은 hpi 파일을 받아 JENKINS_HOME/plugins 에 넣고 재기동해도 된다.3.3 로그인플러그인 설치가 마무리되면, 기본 설치 과정은 모두 끝났다.계정을 생성하고 로그인한다." } ]
